{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKOaHmxB8YMX",
        "outputId": "313509cb-c780-4ac2-d33d-ef86fb924e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul 29 14:09:05 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL3rVxHf89si",
        "outputId": "86ec3cbe-c57a-4f0c-e721-1ee50da5bce7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import time\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "u-kNF_oKA32P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# root_dir\n",
        "root_dir = os.path.abspath(\"/content\")\n",
        "deps_dir = os.path.join(root_dir, \"deps\")\n",
        "repo_dir = os.path.join(root_dir, \"kohya-trainer\")\n",
        "training_dir = os.path.join(root_dir, \"LoRA\")\n",
        "pretrained_model = os.path.join(root_dir, \"pretrained_model\")\n",
        "vae_dir = os.path.join(root_dir, \"vae\")\n",
        "config_dir = os.path.join(training_dir, \"config\")\n",
        "\n",
        "# repo_dir\n",
        "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "tools_dir = os.path.join(repo_dir, \"tools\")\n",
        "finetune_dir = os.path.join(repo_dir, \"finetune\")\n",
        "\n",
        "for store in [\n",
        "    \"root_dir\",\n",
        "    \"deps_dir\",\n",
        "    \"repo_dir\",\n",
        "    \"training_dir\",\n",
        "    \"pretrained_model\",\n",
        "    \"vae_dir\",\n",
        "    \"accelerate_config\",\n",
        "    \"tools_dir\",\n",
        "    \"finetune_dir\",\n",
        "    \"config_dir\",\n",
        "]:\n",
        "    with capture.capture_output() as cap:\n",
        "        del cap"
      ],
      "metadata": {
        "id": "1Kd7tyYH80PG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "安装基础环境"
      ],
      "metadata": {
        "id": "tnHUIBth9RzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo_url = \"https://github.com/Linaqruf/kohya-trainer\"\n",
        "bitsandytes_main_py = \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py\"\n",
        "branch = \"\"\n",
        "install_xformers = True\n",
        "verbose = False\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "\n",
        "def clone_repo(url):\n",
        "    if not os.path.exists(repo_dir):\n",
        "        os.chdir(root_dir)\n",
        "        !git clone {url} {repo_dir}\n",
        "    else:\n",
        "        os.chdir(repo_dir)\n",
        "        !git pull origin {branch} if branch else !git pull\n",
        "\n",
        "\n",
        "def install_dependencies():\n",
        "    s = getoutput('nvidia-smi')\n",
        "\n",
        "    !pip install {'-q' if not verbose else ''} --upgrade -r requirements.txt\n",
        "    !pip install {'-q' if not verbose else ''} torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchaudio==2.0.1+cu118 torchtext==0.15.1 torchdata==0.6.0 --extra-index-url https://download.pytorch.org/whl/cu118 -U\n",
        "\n",
        "    if install_xformers:\n",
        "        !pip install {'-q' if not verbose else ''} xformers==0.0.19 triton==2.0.0 -U\n",
        "\n",
        "    from accelerate.utils import write_basic_config\n",
        "\n",
        "    if not os.path.exists(accelerate_config):\n",
        "        write_basic_config(save_location=accelerate_config)\n",
        "\n",
        "\n",
        "def main():\n",
        "    os.chdir(root_dir)\n",
        "\n",
        "    for dir in [\n",
        "        deps_dir,\n",
        "        training_dir,\n",
        "        config_dir,\n",
        "        pretrained_model,\n",
        "        vae_dir\n",
        "    ]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "    clone_repo(repo_url)\n",
        "\n",
        "    os.chdir(repo_dir)\n",
        "    !apt --fix-broken install\n",
        "    !apt install aria2 {'-qq' if not verbose else ''}\n",
        "\n",
        "    install_dependencies()\n",
        "    time.sleep(3)\n",
        "\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "\n",
        "    cuda_path = \"/usr/local/cuda-11.8/targets/x86_64-linux/lib/\"\n",
        "    ld_library_path = os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
        "    os.environ[\"LD_LIBRARY_PATH\"] = f\"{ld_library_path}:{cuda_path}\"\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOH4vjKo9Bru",
        "outputId": "666685a9-8d0d-4a75-9532-6890285d3bd7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/kohya-trainer'...\n",
            "remote: Enumerating objects: 2315, done.\u001b[K\n",
            "remote: Counting objects: 100% (981/981), done.\u001b[K\n",
            "remote: Compressing objects: 100% (288/288), done.\u001b[K\n",
            "remote: Total 2315 (delta 757), reused 795 (delta 693), pack-reused 1334\u001b[K\n",
            "Receiving objects: 100% (2315/2315), 4.68 MiB | 18.42 MiB/s, done.\n",
            "Resolving deltas: 100% (1514/1514), done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 9 not upgraded.\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 9 not upgraded.\n",
            "Need to get 1,513 kB of archives.\n",
            "After this operation, 5,441 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 120493 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.1/503.1 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.8/599.8 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m729.2/729.2 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.0/115.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dadaptation (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for library (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for elfinder-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m482.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.2/108.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "下载基础模型"
      ],
      "metadata": {
        "id": "3AN0e9gf-L-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"Animefull-final-pruned\": \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/models/animefull-final-pruned.ckpt\",\n",
        "# \"Anything-v3-1\": \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\",\n",
        "# \"AnyLoRA\": \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/AnyLoRA_noVae_fp16-pruned.safetensors\",\n",
        "# \"AnyLoRA-anime-mix\": \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AAM_Anylora_AnimeMix.safetensors\",\n",
        "# \"AnimePastelDream\": \"https://huggingface.co/Lykon/AnimePastelDream/resolve/main/AnimePastelDream_Soft_noVae_fp16.safetensors\",\n",
        "# \"Chillout-mix\": \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/chillout_mix-pruned.safetensors\",\n",
        "# \"OpenJourney-v4\": \"https://huggingface.co/prompthero/openjourney-v4/resolve/main/openjourney-v4.ckpt\",\n",
        "# \"Stable-Diffusion-v1-5\": \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\""
      ],
      "metadata": {
        "id": "YR74ThL19Z1Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 下载你要用的基础模型。这些我用的是AnyLoRA基础模型，你可以根据喜欢进行更换。\n",
        "# 真人风格推荐用Chillout-mix 这类模型\n",
        "# 卡通风格推荐AnyLoRA、Anything这类模型\n",
        "pretrained_model_name_or_path = \"/content/pretrained_model/AnyLoRA_noVae_fp16-pruned.safetensors\"\n",
        "!wget -c https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/AnyLoRA_noVae_fp16-pruned.safetensors -O $pretrained_model_name_or_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDArHtcG-ZyZ",
        "outputId": "21206185-bb09-4c97-cac8-847db9c71036"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-29 14:18:58--  https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/AnyLoRA_noVae_fp16-pruned.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.124, 18.172.134.88, 18.172.134.4, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/5a/ee/5aee850f9c8f5f5951a0b13b59f0d0ae7bbd0ede690503120d02c76550f28b4c/1a0d5ff860b8cddadd51b2122f14f13e8301d5f70fdef1b0ddfdc6a36fe2382c?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27AnyLoRA_noVae_fp16-pruned.safetensors%3B+filename%3D%22AnyLoRA_noVae_fp16-pruned.safetensors%22%3B&Expires=1690885267&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MDg4NTI2N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy81YS9lZS81YWVlODUwZjljOGY1ZjU5NTFhMGIxM2I1OWYwZDBhZTdiYmQwZWRlNjkwNTAzMTIwZDAyYzc2NTUwZjI4YjRjLzFhMGQ1ZmY4NjBiOGNkZGFkZDUxYjIxMjJmMTRmMTNlODMwMWQ1ZjcwZmRlZjFiMGRkZmRjNmEzNmZlMjM4MmM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=oDFiIw6XDTB8J0yzlv-j2EfCiOI5mYfBy4qLEbfOqR1IMOW8MrkqWBzcxukpBWY%7EwS4PtF-1uCBU0fwIYQ2UP2MLL8hWtQ3OPDWgwHl-h2yTery%7EPakozzybPf9qH%7EWaswe6SuAzU05GkTPwJ66zB9GAqI1Ts%7EstZMLWNLZ5AiJQtzvcNmLQz2bhB9gcqzxu8duZt0GSTeqVQWwtZjCt8kO6cq301JG9-RX8t4-lr06hGIwq9DiN4VUPokfNjoMgXdt8VKoIQVu0filTzwqPyYnKfIBEKqsM7cyWgzvqgu2o5eCld8bvoJEOpRhyXmOD3bgHsfatUwKYMg%7EYndVgBw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-07-29 14:18:58--  https://cdn-lfs.huggingface.co/repos/5a/ee/5aee850f9c8f5f5951a0b13b59f0d0ae7bbd0ede690503120d02c76550f28b4c/1a0d5ff860b8cddadd51b2122f14f13e8301d5f70fdef1b0ddfdc6a36fe2382c?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27AnyLoRA_noVae_fp16-pruned.safetensors%3B+filename%3D%22AnyLoRA_noVae_fp16-pruned.safetensors%22%3B&Expires=1690885267&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MDg4NTI2N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy81YS9lZS81YWVlODUwZjljOGY1ZjU5NTFhMGIxM2I1OWYwZDBhZTdiYmQwZWRlNjkwNTAzMTIwZDAyYzc2NTUwZjI4YjRjLzFhMGQ1ZmY4NjBiOGNkZGFkZDUxYjIxMjJmMTRmMTNlODMwMWQ1ZjcwZmRlZjFiMGRkZmRjNmEzNmZlMjM4MmM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=oDFiIw6XDTB8J0yzlv-j2EfCiOI5mYfBy4qLEbfOqR1IMOW8MrkqWBzcxukpBWY%7EwS4PtF-1uCBU0fwIYQ2UP2MLL8hWtQ3OPDWgwHl-h2yTery%7EPakozzybPf9qH%7EWaswe6SuAzU05GkTPwJ66zB9GAqI1Ts%7EstZMLWNLZ5AiJQtzvcNmLQz2bhB9gcqzxu8duZt0GSTeqVQWwtZjCt8kO6cq301JG9-RX8t4-lr06hGIwq9DiN4VUPokfNjoMgXdt8VKoIQVu0filTzwqPyYnKfIBEKqsM7cyWgzvqgu2o5eCld8bvoJEOpRhyXmOD3bgHsfatUwKYMg%7EYndVgBw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.27, 18.154.185.64, 18.154.185.26, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.27|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "准备数据"
      ],
      "metadata": {
        "id": "dwbHq_3k-ri1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = os.path.join(root_dir, \"LoRA/train_data/hb_cartoon\")\n",
        "os.makedirs(train_data_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Your train data directory : {train_data_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa4sdqtY-i6G",
        "outputId": "77f1af01-f3d7-42ac-9c5f-4baf50f9b492"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your train data directory : /content/LoRA/train_data/hb_cartoon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **操作说明: 需要将你准备的照片放置在上面的路径下，比如这里的路径是：/content/LoRA/train_data/hb_cartoon。直接将图片拖到文件夹中就行！确保文件上传完成后，到下一步。10图以上，多少随意。**"
      ],
      "metadata": {
        "id": "-7xlSQ92_3Wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用BLIP模型给你的图片加上prompt，用于训练。\n",
        "\n",
        "import os\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "\n",
        "batch_size = 8\n",
        "max_data_loader_n_workers = 2\n",
        "beam_search = True\n",
        "min_length = 5\n",
        "max_length = 75\n",
        "recursive = False\n",
        "verbose_logging = True\n",
        "\n",
        "config = {\n",
        "    \"_train_data_dir\" : train_data_dir,\n",
        "    \"batch_size\" : batch_size,\n",
        "    \"beam_search\" : beam_search,\n",
        "    \"min_length\" : min_length,\n",
        "    \"max_length\" : max_length,\n",
        "    \"debug\" : verbose_logging,\n",
        "    \"caption_extension\" : \".caption\",\n",
        "    \"max_data_loader_n_workers\" : max_data_loader_n_workers,\n",
        "    \"recursive\" : recursive\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python make_captions.py {args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{final_args}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bKEjOIe-0Sj",
        "outputId": "26b49319-9861-4901-9b1f-b9736bd75a8d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load images from /content/LoRA/train_data/hb_cartoon\n",
            "found 10 images.\n",
            "loading BLIP caption: https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 7.52MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 196kB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 570/570 [00:00<00:00, 3.15MB/s]\n",
            "100% 1.66G/1.66G [00:11<00:00, 154MB/s]\n",
            "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "BLIP loaded\n",
            "  0% 0/2 [00:00<?, ?it/s]/content/LoRA/train_data/hb_cartoon/liuyifei1.jpg a woman in a purple dress smiles at the camera\n",
            "/content/LoRA/train_data/hb_cartoon/liuyifei10.jpg a woman in a blue shirt is smiling\n",
            "/content/LoRA/train_data/hb_cartoon/liuyifei2.jpg a woman with long hair wearing a necklace\n",
            "/content/LoRA/train_data/hb_cartoon/liuyifei3.jpg a woman with long hair and a white sweater\n",
            "/content/LoRA/train_data/hb_cartoon/liuyifei4.jpg a woman with long hair and a white shirt\n",
            "/content/LoRA/train_data/hb_cartoon/liuyifei5.jpg a woman with a necklace and earrings on\n",
            "/content/LoRA/train_data/hb_cartoon/liuyifei6.jpg a woman with long hair sitting on a chair\n",
            "/content/LoRA/train_data/hb_cartoon/liuyifei7.jpg a woman in a red jacket is posing for a picture\n",
            "100% 2/2 [00:10<00:00,  5.18s/it]\n",
            "/content/LoRA/train_data/hb_cartoon/liuyifei8.jpg a woman with long hair wearing a suit and red lipstick\n",
            "/content/LoRA/train_data/hb_cartoon/liuyifei9.jpg a woman holding a glass of juice in her hand\n",
            "done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "训练配置"
      ],
      "metadata": {
        "id": "H-oNLmEyMic3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_name = \"hb_pro\"\n",
        "vae = \"\"\n",
        "output_dir = os.path.join(root_dir, \"LoRA/output/hb_pro\")\n",
        "\n",
        "sample_dir = os.path.join(output_dir, \"sample\")\n",
        "for dir in [output_dir, sample_dir]:\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "print(\"Project Name: \", project_name)\n",
        "print(\n",
        "    \"Pretrained Model Path: \", pretrained_model_name_or_path\n",
        ") if pretrained_model_name_or_path else print(\"No Pretrained Model path specified.\")\n",
        "\n",
        "print(\"VAE Path: \", vae) if vae else print(\"No VAE path specified.\")\n",
        "print(\"Output Path: \", output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMv2gmZZMg-C",
        "outputId": "d9b05162-3cc3-4b46-e75b-ac91d85c914a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project Name:  hb_pro\n",
            "Pretrained Model Path:  /content/pretrained_model/AnyLoRA_noVae_fp16-pruned.safetensors\n",
            "No VAE path specified.\n",
            "Output Path:  /content/LoRA/output/hb_pro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import toml\n",
        "import glob\n",
        "\n",
        "dataset_repeats = 10\n",
        "activation_word = \"\"\n",
        "caption_extension = \".caption\"\n",
        "resolution = 512\n",
        "flip_aug = True\n",
        "keep_tokens = 0\n",
        "\n",
        "def parse_folder_name(folder_name, default_num_repeats, default_class_token):\n",
        "    folder_name_parts = folder_name.split(\"_\")\n",
        "\n",
        "    if len(folder_name_parts) == 2:\n",
        "        if folder_name_parts[0].isdigit():\n",
        "            num_repeats = int(folder_name_parts[0])\n",
        "            class_token = folder_name_parts[1].replace(\"_\", \" \")\n",
        "        else:\n",
        "            num_repeats = default_num_repeats\n",
        "            class_token = default_class_token\n",
        "    else:\n",
        "        num_repeats = default_num_repeats\n",
        "        class_token = default_class_token\n",
        "\n",
        "    return num_repeats, class_token\n",
        "\n",
        "def find_image_files(path):\n",
        "    supported_extensions = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")\n",
        "    return [file for file in glob.glob(path + '/**/*', recursive=True) if file.lower().endswith(supported_extensions)]\n",
        "\n",
        "def process_data_dir(data_dir, default_num_repeats, default_class_token, is_reg=False):\n",
        "    subsets = []\n",
        "\n",
        "    images = find_image_files(data_dir)\n",
        "    if images:\n",
        "        subsets.append({\n",
        "            \"image_dir\": data_dir,\n",
        "            \"class_tokens\": default_class_token,\n",
        "            \"num_repeats\": default_num_repeats,\n",
        "            **({\"is_reg\": is_reg} if is_reg else {}),\n",
        "        })\n",
        "\n",
        "    for root, dirs, files in os.walk(data_dir):\n",
        "        for folder in dirs:\n",
        "            folder_path = os.path.join(root, folder)\n",
        "            images = find_image_files(folder_path)\n",
        "\n",
        "            if images:\n",
        "                num_repeats, class_token = parse_folder_name(folder, default_num_repeats, default_class_token)\n",
        "\n",
        "                subset = {\n",
        "                    \"image_dir\": folder_path,\n",
        "                    \"class_tokens\": class_token,\n",
        "                    \"num_repeats\": num_repeats,\n",
        "                }\n",
        "\n",
        "                if is_reg:\n",
        "                    subset[\"is_reg\"] = True\n",
        "\n",
        "                subsets.append(subset)\n",
        "\n",
        "    return subsets\n",
        "\n",
        "\n",
        "train_subsets = process_data_dir(train_data_dir, dataset_repeats, activation_word)\n",
        "print(train_subsets)\n",
        "# reg_subsets = process_data_dir(reg_data_dir, dataset_repeats, activation_word, is_reg=True)\n",
        "\n",
        "# subsets = train_subsets + reg_subsets\n",
        "subsets = train_subsets\n",
        "\n",
        "config = {\n",
        "    \"general\": {\n",
        "        \"enable_bucket\": True,\n",
        "        \"caption_extension\": caption_extension,\n",
        "        \"shuffle_caption\": True,\n",
        "        \"keep_tokens\": keep_tokens,\n",
        "        \"bucket_reso_steps\": 64,\n",
        "        \"bucket_no_upscale\": False,\n",
        "    },\n",
        "    \"datasets\": [\n",
        "        {\n",
        "            \"resolution\": resolution,\n",
        "            \"min_bucket_reso\": 320 if resolution > 640 else 256,\n",
        "            \"max_bucket_reso\": 1280 if resolution > 640 else 1024,\n",
        "            \"caption_dropout_rate\": 0,\n",
        "            \"caption_tag_dropout_rate\": 0,\n",
        "            \"caption_dropout_every_n_epochs\": 0,\n",
        "            \"flip_aug\": flip_aug,\n",
        "            \"color_aug\": False,\n",
        "            \"face_crop_aug_range\": None,\n",
        "            \"subsets\": subsets,\n",
        "        }\n",
        "    ],\n",
        "}\n",
        "\n",
        "dataset_config = os.path.join(config_dir, \"dataset_config.toml\")\n",
        "\n",
        "for key in config:\n",
        "    if isinstance(config[key], dict):\n",
        "        for sub_key in config[key]:\n",
        "            if config[key][sub_key] == \"\":\n",
        "                config[key][sub_key] = None\n",
        "    elif config[key] == \"\":\n",
        "        config[key] = None\n",
        "\n",
        "config_str = toml.dumps(config)\n",
        "\n",
        "with open(dataset_config, \"w\") as f:\n",
        "    f.write(config_str)\n",
        "\n",
        "print(config_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90LnMgMD_QOO",
        "outputId": "0846c3dc-6f45-4f64-fec5-aff371a22cf9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'image_dir': '/content/LoRA/train_data/hb_cartoon', 'class_tokens': '', 'num_repeats': 10}]\n",
            "[[datasets]]\n",
            "resolution = 512\n",
            "min_bucket_reso = 256\n",
            "max_bucket_reso = 1024\n",
            "caption_dropout_rate = 0\n",
            "caption_tag_dropout_rate = 0\n",
            "caption_dropout_every_n_epochs = 0\n",
            "flip_aug = true\n",
            "color_aug = false\n",
            "[[datasets.subsets]]\n",
            "image_dir = \"/content/LoRA/train_data/hb_cartoon\"\n",
            "class_tokens = \"\"\n",
            "num_repeats = 10\n",
            "\n",
            "\n",
            "[general]\n",
            "enable_bucket = true\n",
            "caption_extension = \".caption\"\n",
            "shuffle_caption = true\n",
            "keep_tokens = 0\n",
            "bucket_reso_steps = 64\n",
            "bucket_no_upscale = false\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network_category = \"LoRA\"\n",
        "\n",
        "conv_dim = 32\n",
        "conv_alpha = 16\n",
        "network_dim = 32\n",
        "network_alpha = 16\n",
        "network_weight = \"\"\n",
        "network_module = \"lycoris.kohya\" if network_category in [\"LoHa\", \"LoCon_Lycoris\"] else \"networks.lora\"\n",
        "network_args = \"\" if network_category == \"LoRA\" else [\n",
        "    f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\",\n",
        "    ]\n",
        "\n",
        "min_snr_gamma = -1\n",
        "optimizer_type = \"AdamW8bit\"\n",
        "optimizer_args = \"\"\n",
        "train_unet = True\n",
        "unet_lr = 1e-4\n",
        "train_text_encoder = True\n",
        "text_encoder_lr = 5e-5\n",
        "lr_scheduler = \"constant\"\n",
        "lr_warmup_steps = 0\n",
        "lr_scheduler_num_cycles = 0\n",
        "lr_scheduler_power = 0\n",
        "\n",
        "if network_category == \"LoHa\":\n",
        "  network_args.append(\"algo=loha\")\n",
        "elif network_category == \"LoCon_Lycoris\":\n",
        "  network_args.append(\"algo=lora\")\n",
        "\n",
        "print(\"- LoRA Config:\")\n",
        "print(f\"  - Min-SNR Weighting: {min_snr_gamma}\") if not min_snr_gamma == -1 else \"\"\n",
        "print(f\"  - Loading network module: {network_module}\")\n",
        "if not network_category == \"LoRA\":\n",
        "  print(f\"  - network args: {network_args}\")\n",
        "print(f\"  - {network_module} linear_dim set to: {network_dim}\")\n",
        "print(f\"  - {network_module} linear_alpha set to: {network_alpha}\")\n",
        "if not network_category == \"LoRA\":\n",
        "  print(f\"  - {network_module} conv_dim set to: {conv_dim}\")\n",
        "  print(f\"  - {network_module} conv_alpha set to: {conv_alpha}\")\n",
        "\n",
        "if not network_weight:\n",
        "    print(\"  - No LoRA weight loaded.\")\n",
        "else:\n",
        "    if os.path.exists(network_weight):\n",
        "        print(f\"  - Loading LoRA weight: {network_weight}\")\n",
        "    else:\n",
        "        print(f\"  - {network_weight} does not exist.\")\n",
        "        network_weight = \"\"\n",
        "\n",
        "print(\"- Optimizer Config:\")\n",
        "print(f\"  - Additional network category: {network_category}\")\n",
        "print(f\"  - Using {optimizer_type} as Optimizer\")\n",
        "if optimizer_args:\n",
        "    print(f\"  - Optimizer Args: {optimizer_args}\")\n",
        "if train_unet and train_text_encoder:\n",
        "    print(\"  - Train UNet and Text Encoder\")\n",
        "    print(f\"    - UNet learning rate: {unet_lr}\")\n",
        "    print(f\"    - Text encoder learning rate: {text_encoder_lr}\")\n",
        "if train_unet and not train_text_encoder:\n",
        "    print(\"  - Train UNet only\")\n",
        "    print(f\"    - UNet learning rate: {unet_lr}\")\n",
        "if train_text_encoder and not train_unet:\n",
        "    print(\"  - Train Text Encoder only\")\n",
        "    print(f\"    - Text encoder learning rate: {text_encoder_lr}\")\n",
        "print(f\"  - Learning rate warmup steps: {lr_warmup_steps}\")\n",
        "print(f\"  - Learning rate Scheduler: {lr_scheduler}\")\n",
        "if lr_scheduler == \"cosine_with_restarts\":\n",
        "    print(f\"  - lr_scheduler_num_cycles: {lr_scheduler_num_cycles}\")\n",
        "elif lr_scheduler == \"polynomial\":\n",
        "    print(f\"  - lr_scheduler_power: {lr_scheduler_power}\")"
      ],
      "metadata": {
        "id": "NSf_JvU6_0Lk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47878d53-7745-4e00-9185-33491b1f07fd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- LoRA Config:\n",
            "  - Loading network module: networks.lora\n",
            "  - networks.lora linear_dim set to: 32\n",
            "  - networks.lora linear_alpha set to: 16\n",
            "  - No LoRA weight loaded.\n",
            "- Optimizer Config:\n",
            "  - Additional network category: LoRA\n",
            "  - Using AdamW8bit as Optimizer\n",
            "  - Train UNet and Text Encoder\n",
            "    - UNet learning rate: 0.0001\n",
            "    - Text encoder learning rate: 5e-05\n",
            "  - Learning rate warmup steps: 0\n",
            "  - Learning rate Scheduler: constant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import toml\n",
        "import os\n",
        "\n",
        "lowram = True\n",
        "enable_sample_prompt = True\n",
        "sampler = \"ddim\"  #[\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "noise_offset = 0.0\n",
        "num_epochs = 10\n",
        "vae_batch_size = 4\n",
        "train_batch_size = 6\n",
        "mixed_precision = \"fp16\"  # [\"no\",\"fp16\",\"bf16\"]\n",
        "save_precision = \"fp16\"  #  [\"float\", \"fp16\", \"bf16\"]\n",
        "save_n_epochs_type = \"save_every_n_epochs\"\n",
        "save_n_epochs_type_value = 1\n",
        "save_model_as = \"safetensors\"  # [\"ckpt\", \"pt\", \"safetensors\"]\n",
        "max_token_length = 225\n",
        "clip_skip = 2\n",
        "gradient_checkpointing = False\n",
        "gradient_accumulation_steps = 1\n",
        "seed = -1\n",
        "logging_dir = os.path.join(root_dir, \"LoRA/logs\")\n",
        "prior_loss_weight = 1.0\n",
        "os.chdir(repo_dir)\n",
        "\n",
        "sample_str = f\"\"\"\n",
        "  masterpiece, best quality, a woman with a very short haircut and a pink shirt, looking at viewer, simple background \\\n",
        "  --n lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry \\\n",
        "  --w 512 \\\n",
        "  --h 512 \\\n",
        "  --l 7 \\\n",
        "  --s 28\n",
        "\"\"\"\n",
        "\n",
        "config = {\n",
        "    \"model_arguments\": {\n",
        "        \"v2\": False,\n",
        "        \"v_parameterization\": False,\n",
        "        \"pretrained_model_name_or_path\": pretrained_model_name_or_path,\n",
        "        \"vae\": vae,\n",
        "    },\n",
        "    \"additional_network_arguments\": {\n",
        "        \"no_metadata\": False,\n",
        "        \"unet_lr\": float(unet_lr) if train_unet else None,\n",
        "        \"text_encoder_lr\": float(text_encoder_lr) if train_text_encoder else None,\n",
        "        \"network_weights\": network_weight,\n",
        "        \"network_module\": network_module,\n",
        "        \"network_dim\": network_dim,\n",
        "        \"network_alpha\": network_alpha,\n",
        "        \"network_args\": network_args,\n",
        "        \"network_train_unet_only\": True if train_unet and not train_text_encoder else False,\n",
        "        \"network_train_text_encoder_only\": True if train_text_encoder and not train_unet else False,\n",
        "        \"training_comment\": None,\n",
        "    },\n",
        "    \"optimizer_arguments\": {\n",
        "        \"min_snr_gamma\": min_snr_gamma if not min_snr_gamma == -1 else None,\n",
        "        \"optimizer_type\": optimizer_type,\n",
        "        \"learning_rate\": unet_lr,\n",
        "        \"max_grad_norm\": 1.0,\n",
        "        \"optimizer_args\": eval(optimizer_args) if optimizer_args else None,\n",
        "        \"lr_scheduler\": lr_scheduler,\n",
        "        \"lr_warmup_steps\": lr_warmup_steps,\n",
        "        \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles if lr_scheduler == \"cosine_with_restarts\" else None,\n",
        "        \"lr_scheduler_power\": lr_scheduler_power if lr_scheduler == \"polynomial\" else None,\n",
        "    },\n",
        "    \"dataset_arguments\": {\n",
        "        \"cache_latents\": True,\n",
        "        \"debug_dataset\": False,\n",
        "        \"vae_batch_size\": vae_batch_size,\n",
        "    },\n",
        "    \"training_arguments\": {\n",
        "        \"output_dir\": output_dir,\n",
        "        \"output_name\": project_name,\n",
        "        \"save_precision\": save_precision,\n",
        "        \"save_every_n_epochs\": save_n_epochs_type_value if save_n_epochs_type == \"save_every_n_epochs\" else None,\n",
        "        \"save_n_epoch_ratio\": save_n_epochs_type_value if save_n_epochs_type == \"save_n_epoch_ratio\" else None,\n",
        "        \"save_last_n_epochs\": None,\n",
        "        \"save_state\": None,\n",
        "        \"save_last_n_epochs_state\": None,\n",
        "        \"resume\": None,\n",
        "        \"train_batch_size\": train_batch_size,\n",
        "        \"max_token_length\": 225,\n",
        "        \"mem_eff_attn\": False,\n",
        "        \"xformers\": True,\n",
        "        \"max_train_epochs\": num_epochs,\n",
        "        \"max_data_loader_n_workers\": 8,\n",
        "        \"persistent_data_loader_workers\": True,\n",
        "        \"seed\": seed if seed > 0 else None,\n",
        "        \"gradient_checkpointing\": gradient_checkpointing,\n",
        "        \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
        "        \"mixed_precision\": mixed_precision,\n",
        "        \"clip_skip\": clip_skip,\n",
        "        \"logging_dir\": logging_dir,\n",
        "        \"log_prefix\": project_name,\n",
        "        \"noise_offset\": noise_offset if noise_offset > 0 else None,\n",
        "        \"lowram\": lowram,\n",
        "    },\n",
        "    \"sample_prompt_arguments\": {\n",
        "        \"sample_every_n_steps\": None,\n",
        "        \"sample_every_n_epochs\": 1 if enable_sample_prompt else 999999,\n",
        "        \"sample_sampler\": sampler,\n",
        "    },\n",
        "    \"dreambooth_arguments\": {\n",
        "        \"prior_loss_weight\": 1.0,\n",
        "    },\n",
        "    \"saving_arguments\": {\n",
        "        \"save_model_as\": save_model_as\n",
        "    },\n",
        "}\n",
        "\n",
        "config_path = os.path.join(config_dir, \"config_file.toml\")\n",
        "prompt_path = os.path.join(config_dir, \"sample_prompt.txt\")\n",
        "\n",
        "\n",
        "for key in config:\n",
        "    if isinstance(config[key], dict):\n",
        "        for sub_key in config[key]:\n",
        "            if config[key][sub_key] == \"\":\n",
        "                config[key][sub_key] = None\n",
        "    elif config[key] == \"\":\n",
        "        config[key] = None\n",
        "\n",
        "config_str = toml.dumps(config)\n",
        "\n",
        "write_file(config_path, config_str)\n",
        "write_file(prompt_path, sample_str)\n",
        "\n",
        "print(config_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCrsnXwvNHQp",
        "outputId": "3f88ef25-ba83-444b-f965-c643b581adaa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[model_arguments]\n",
            "v2 = false\n",
            "v_parameterization = false\n",
            "pretrained_model_name_or_path = \"/content/pretrained_model/AnyLoRA_noVae_fp16-pruned.safetensors\"\n",
            "\n",
            "[additional_network_arguments]\n",
            "no_metadata = false\n",
            "unet_lr = 0.0001\n",
            "text_encoder_lr = 5e-5\n",
            "network_module = \"networks.lora\"\n",
            "network_dim = 32\n",
            "network_alpha = 16\n",
            "network_train_unet_only = false\n",
            "network_train_text_encoder_only = false\n",
            "\n",
            "[optimizer_arguments]\n",
            "optimizer_type = \"AdamW8bit\"\n",
            "learning_rate = 0.0001\n",
            "max_grad_norm = 1.0\n",
            "lr_scheduler = \"constant\"\n",
            "lr_warmup_steps = 0\n",
            "\n",
            "[dataset_arguments]\n",
            "cache_latents = true\n",
            "debug_dataset = false\n",
            "vae_batch_size = 4\n",
            "\n",
            "[training_arguments]\n",
            "output_dir = \"/content/LoRA/output/hb_pro\"\n",
            "output_name = \"hb_pro\"\n",
            "save_precision = \"fp16\"\n",
            "save_every_n_epochs = 1\n",
            "train_batch_size = 6\n",
            "max_token_length = 225\n",
            "mem_eff_attn = false\n",
            "xformers = true\n",
            "max_train_epochs = 10\n",
            "max_data_loader_n_workers = 8\n",
            "persistent_data_loader_workers = true\n",
            "gradient_checkpointing = false\n",
            "gradient_accumulation_steps = 1\n",
            "mixed_precision = \"fp16\"\n",
            "clip_skip = 2\n",
            "logging_dir = \"/content/LoRA/logs\"\n",
            "log_prefix = \"hb_pro\"\n",
            "lowram = true\n",
            "\n",
            "[sample_prompt_arguments]\n",
            "sample_every_n_epochs = 1\n",
            "sample_sampler = \"ddim\"\n",
            "\n",
            "[dreambooth_arguments]\n",
            "prior_loss_weight = 1.0\n",
            "\n",
            "[saving_arguments]\n",
            "save_model_as = \"safetensors\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "训练起来！过程中你可以在LoRA/output/hb_pro/sample目录下看训练过程中的图像生成效果。用于选择自己满意的LoRA模型。"
      ],
      "metadata": {
        "id": "yHMu-aazNbE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_prompt = os.path.join(config_dir, \"sample_prompt.txt\")\n",
        "config_file = os.path.join(config_dir, \"config_file.toml\")\n",
        "dataset_config = os.path.join(config_dir, \"dataset_config.toml\")\n",
        "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "\n",
        "accelerate_conf = {\n",
        "    \"config_file\" : accelerate_config,\n",
        "    \"num_cpu_threads_per_process\" : 1,\n",
        "}\n",
        "\n",
        "train_conf = {\n",
        "    \"sample_prompts\" : sample_prompt,\n",
        "    \"dataset_config\" : dataset_config,\n",
        "    \"config_file\" : config_file\n",
        "}\n",
        "\n",
        "def train(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "accelerate_args = train(accelerate_conf)\n",
        "train_args = train(train_conf)\n",
        "final_args = f\"accelerate launch {accelerate_args} train_network.py {train_args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cz2_7bONXq_",
        "outputId": "f27c86c6-3f14-4ef7-c760-cac546797b65"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading settings from /content/LoRA/config/config_file.toml...\n",
            "/content/LoRA/config/config_file\n",
            "prepare tokenizer\n",
            "Downloading (…)olve/main/vocab.json: 100% 961k/961k [00:00<00:00, 18.3MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 525k/525k [00:00<00:00, 11.4MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 389/389 [00:00<00:00, 1.79MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 905/905 [00:00<00:00, 4.82MB/s]\n",
            "update token length: 225\n",
            "Load dataset config from /content/LoRA/config/dataset_config.toml\n",
            "prepare images.\n",
            "found directory /content/LoRA/train_data/hb_cartoon contains 10 image files\n",
            "100 train images with repeating.\n",
            "0 reg images.\n",
            "no regularization images / 正則化画像が見つかりませんでした\n",
            "[Dataset 0]\n",
            "  batch_size: 6\n",
            "  resolution: (512, 512)\n",
            "  enable_bucket: True\n",
            "  min_bucket_reso: 256\n",
            "  max_bucket_reso: 1024\n",
            "  bucket_reso_steps: 64\n",
            "  bucket_no_upscale: False\n",
            "\n",
            "  [Subset 0 of Dataset 0]\n",
            "    image_dir: \"/content/LoRA/train_data/hb_cartoon\"\n",
            "    image_count: 10\n",
            "    num_repeats: 10\n",
            "    shuffle_caption: True\n",
            "    keep_tokens: 0\n",
            "    caption_dropout_rate: 0\n",
            "    caption_dropout_every_n_epoches: 0\n",
            "    caption_tag_dropout_rate: 0\n",
            "    color_aug: False\n",
            "    flip_aug: True\n",
            "    face_crop_aug_range: None\n",
            "    random_crop: False\n",
            "    token_warmup_min: 1,\n",
            "    token_warmup_step: 0,\n",
            "    is_reg: False\n",
            "    class_tokens: \n",
            "    caption_extension: .caption\n",
            "\n",
            "\n",
            "[Dataset 0]\n",
            "loading image sizes.\n",
            "100% 10/10 [00:00<00:00, 402.68it/s]\n",
            "make buckets\n",
            "number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）\n",
            "bucket 0: resolution (384, 640), count: 40\n",
            "bucket 1: resolution (448, 576), count: 30\n",
            "bucket 2: resolution (576, 448), count: 10\n",
            "bucket 3: resolution (640, 384), count: 20\n",
            "mean ar error (without repeats): 0.080208983626815\n",
            "prepare accelerator\n",
            "Using accelerator 0.15.0 or above.\n",
            "loading model for process 0/1\n",
            "load StableDiffusion checkpoint\n",
            "loading u-net: <All keys matched successfully>\n",
            "loading vae: <All keys matched successfully>\n",
            "Downloading (…)lve/main/config.json: 100% 4.52k/4.52k [00:00<00:00, 22.4MB/s]\n",
            "Downloading pytorch_model.bin: 100% 1.71G/1.71G [00:23<00:00, 74.1MB/s]\n",
            "loading text encoder: <All keys matched successfully>\n",
            "Replace CrossAttention.forward to use xformers\n",
            "[Dataset 0]\n",
            "caching latents.\n",
            "100% 6/6 [00:09<00:00,  1.56s/it]\n",
            "import network module: networks.lora\n",
            "create LoRA network. base dim (rank): 32, alpha: 16\n",
            "create LoRA for Text Encoder: 72 modules.\n",
            "create LoRA for U-Net: 192 modules.\n",
            "enable LoRA for text encoder\n",
            "enable LoRA for U-Net\n",
            "prepare optimizer, data loader etc.\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
            "================================================================================\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda-11.8/targets/x86_64-linux/lib/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "use 8-bit AdamW optimizer | {}\n",
            "override steps. steps for 10 epochs is / 指定エポックまでのステップ数: 180\n",
            "running training / 学習開始\n",
            "  num train images * repeats / 学習画像の数×繰り返し回数: 100\n",
            "  num reg images / 正則化画像の数: 0\n",
            "  num batches per epoch / 1epochのバッチ数: 18\n",
            "  num epochs / epoch数: 10\n",
            "  batch size per device / バッチサイズ: 6\n",
            "  gradient accumulation steps / 勾配を合計するステップ数 = 1\n",
            "  total optimization steps / 学習ステップ数: 180\n",
            "steps:   0% 0/180 [00:00<?, ?it/s]epoch 1/10\n",
            "steps:  10% 18/180 [00:23<03:33,  1.32s/it, loss=0.141]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000001.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 18\n",
            "prompt: masterpiece, best quality, a woman with a very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:09,  2.80it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:06,  3.93it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:05,  4.47it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:05,  4.77it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:04,  4.95it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  5.07it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  5.16it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:03,  5.21it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  5.23it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:03,  5.27it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  5.29it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  5.31it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:02,  5.31it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  5.32it/s]\u001b[A\n",
            " 54% 15/28 [00:02<00:02,  5.31it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  5.32it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  5.31it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:01,  5.32it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  5.31it/s]\u001b[A\n",
            " 71% 20/28 [00:03<00:01,  5.32it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  5.32it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  5.31it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:00,  5.32it/s]\u001b[A\n",
            " 86% 24/28 [00:04<00:00,  5.32it/s]\u001b[A\n",
            " 89% 25/28 [00:04<00:00,  5.32it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  5.30it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  5.30it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  5.16it/s]\n",
            "epoch 2/10\n",
            "steps:  20% 36/180 [00:54<03:36,  1.50s/it, loss=0.177]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000002.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 36\n",
            "prompt: masterpiece, best quality, a woman with a very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.33it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:04,  5.24it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:04,  5.21it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  5.18it/s]\u001b[A\n",
            " 18% 5/28 [00:00<00:04,  5.08it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  5.09it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  5.12it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:03,  5.12it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  5.13it/s]\u001b[A\n",
            " 36% 10/28 [00:01<00:03,  5.12it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  5.12it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  5.12it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:02,  5.11it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  5.11it/s]\u001b[A\n",
            " 54% 15/28 [00:02<00:02,  5.11it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  5.12it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  5.12it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:01,  5.13it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  5.13it/s]\u001b[A\n",
            " 71% 20/28 [00:03<00:01,  5.12it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  5.12it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  5.13it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:00,  5.12it/s]\u001b[A\n",
            " 86% 24/28 [00:04<00:00,  5.13it/s]\u001b[A\n",
            " 89% 25/28 [00:04<00:00,  5.12it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  5.12it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  5.11it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  5.13it/s]\n",
            "epoch 3/10\n",
            "steps:  30% 54/180 [01:24<03:17,  1.57s/it, loss=0.157]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000003.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 54\n",
            "prompt: masterpiece, best quality, a woman with a very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.05it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  4.90it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:05,  4.95it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  4.93it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:04,  4.84it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  4.88it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  4.91it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:04,  4.92it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  4.92it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:03,  4.90it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  4.89it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  4.90it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  4.91it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  4.91it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  4.91it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.89it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  4.90it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:02,  4.89it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  4.89it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.89it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.90it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  4.91it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:01,  4.90it/s]\u001b[A\n",
            " 86% 24/28 [00:04<00:00,  4.90it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.91it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  4.92it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  4.93it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  4.90it/s]\n",
            "epoch 4/10\n",
            "steps:  40% 72/180 [01:56<02:54,  1.62s/it, loss=0.157]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000004.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 72\n",
            "prompt: masterpiece, best quality, a woman with a very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.08it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  5.04it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:05,  4.31it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:05,  4.56it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:06,  3.79it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:05,  3.77it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:06,  3.08it/s]\u001b[A\n",
            " 29% 8/28 [00:02<00:05,  3.52it/s]\u001b[A\n",
            " 32% 9/28 [00:02<00:04,  3.88it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:04,  3.71it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:04,  4.01it/s]\u001b[A\n",
            " 43% 12/28 [00:03<00:04,  3.62it/s]\u001b[A\n",
            " 46% 13/28 [00:03<00:04,  3.34it/s]\u001b[A\n",
            " 50% 14/28 [00:03<00:04,  2.98it/s]\u001b[A\n",
            " 54% 15/28 [00:04<00:03,  3.40it/s]\u001b[A\n",
            " 57% 16/28 [00:04<00:03,  3.77it/s]\u001b[A\n",
            " 61% 17/28 [00:04<00:02,  4.07it/s]\u001b[A\n",
            " 64% 18/28 [00:04<00:02,  4.27it/s]\u001b[A\n",
            " 68% 19/28 [00:04<00:02,  4.47it/s]\u001b[A\n",
            " 71% 20/28 [00:05<00:01,  4.47it/s]\u001b[A\n",
            " 75% 21/28 [00:05<00:01,  4.14it/s]\u001b[A\n",
            " 79% 22/28 [00:05<00:01,  4.22it/s]\u001b[A\n",
            " 82% 23/28 [00:05<00:01,  4.43it/s]\u001b[A\n",
            " 86% 24/28 [00:06<00:00,  4.19it/s]\u001b[A\n",
            " 89% 25/28 [00:06<00:00,  4.34it/s]\u001b[A\n",
            " 93% 26/28 [00:06<00:00,  4.51it/s]\u001b[A\n",
            " 96% 27/28 [00:06<00:00,  4.06it/s]\u001b[A\n",
            "100% 28/28 [00:07<00:00,  3.97it/s]\n",
            "epoch 5/10\n",
            "steps:  50% 90/180 [02:28<02:28,  1.66s/it, loss=0.131]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000005.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 90\n",
            "prompt: masterpiece, best quality, a woman with a very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.22it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  5.11it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:04,  5.09it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  5.06it/s]\u001b[A\n",
            " 18% 5/28 [00:00<00:04,  5.02it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  5.02it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  5.04it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:03,  5.03it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  5.04it/s]\u001b[A\n",
            " 36% 10/28 [00:01<00:03,  5.04it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  5.04it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  5.03it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  5.00it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  5.02it/s]\u001b[A\n",
            " 54% 15/28 [00:02<00:02,  5.02it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  5.02it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  5.02it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:01,  5.03it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  5.03it/s]\u001b[A\n",
            " 71% 20/28 [00:03<00:01,  4.95it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.89it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  4.94it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:01,  4.96it/s]\u001b[A\n",
            " 86% 24/28 [00:04<00:00,  5.00it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.11it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  3.73it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  3.96it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  4.76it/s]\n",
            "epoch 6/10\n",
            "steps:  60% 108/180 [03:00<02:00,  1.67s/it, loss=0.103]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000006.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 108\n",
            "prompt: masterpiece, best quality, a woman with a very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.15it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  5.06it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:04,  5.02it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  5.01it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:04,  4.92it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  4.94it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  4.96it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:04,  4.96it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  4.96it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:03,  4.96it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  4.97it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  4.97it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  4.97it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  4.97it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  4.96it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.96it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  4.96it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:02,  4.97it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  4.98it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.98it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.98it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  4.97it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:01,  4.96it/s]\u001b[A\n",
            " 86% 24/28 [00:04<00:00,  4.97it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.97it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  4.96it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  4.97it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  4.97it/s]\n",
            "epoch 7/10\n",
            "steps:  70% 126/180 [03:31<01:30,  1.68s/it, loss=0.143]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000007.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 126\n",
            "prompt: masterpiece, best quality, a woman with a very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.04it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  5.04it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:04,  5.02it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  5.03it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:04,  4.96it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  4.97it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  4.98it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:04,  4.98it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  4.99it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:03,  4.99it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  5.01it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  5.00it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  4.99it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  5.00it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  5.00it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.99it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  4.98it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:02,  4.98it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  5.00it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  5.01it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  5.01it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  5.01it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:00,  5.01it/s]\u001b[A\n",
            " 86% 24/28 [00:04<00:00,  4.99it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.99it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  5.00it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  5.00it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  5.00it/s]\n",
            "epoch 8/10\n",
            "steps:  80% 144/180 [04:02<01:00,  1.68s/it, loss=0.136]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000008.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 144\n",
            "prompt: masterpiece, best quality, a woman with a very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.17it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  5.07it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:04,  5.03it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  5.01it/s]\u001b[A\n",
            " 18% 5/28 [00:00<00:04,  4.98it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  5.00it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  5.01it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:03,  5.00it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  5.01it/s]\u001b[A\n",
            " 36% 10/28 [00:01<00:03,  5.00it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  5.00it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  4.99it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  5.00it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  4.99it/s]\u001b[A\n",
            " 54% 15/28 [00:02<00:02,  4.99it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.98it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  4.99it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:02,  5.00it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  5.00it/s]\u001b[A\n",
            " 71% 20/28 [00:03<00:01,  5.00it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.98it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  4.99it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:01,  4.99it/s]\u001b[A\n",
            " 86% 24/28 [00:04<00:00,  4.98it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.97it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  4.98it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  4.98it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  5.00it/s]\n",
            "epoch 9/10\n",
            "steps:  90% 162/180 [04:33<00:30,  1.69s/it, loss=0.138]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000009.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 162\n",
            "prompt: masterpiece, best quality, a woman with a very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.15it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  5.07it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:04,  5.04it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  5.03it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:04,  4.95it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  4.96it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  4.98it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:04,  4.98it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  4.98it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:03,  4.97it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  4.98it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  4.98it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  4.99it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  4.99it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  4.99it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.98it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  4.98it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:02,  4.98it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  4.99it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.98it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.97it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  4.98it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:01,  4.97it/s]\u001b[A\n",
            " 86% 24/28 [00:04<00:00,  4.97it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.98it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  4.98it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  4.98it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  4.98it/s]\n",
            "epoch 10/10\n",
            "steps: 100% 180/180 [05:03<00:00,  1.69s/it, loss=0.119]generating sample images at step / サンプル画像生成 ステップ: 180\n",
            "prompt: masterpiece, best quality, a woman with a very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.15it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  5.07it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:04,  5.04it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  5.02it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:04,  4.92it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  4.95it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  4.97it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:04,  4.97it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  4.98it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:03,  4.99it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  4.97it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  4.96it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  4.96it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  4.97it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  4.97it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.97it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  4.98it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:02,  4.97it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  4.97it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.98it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.99it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  4.98it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:01,  4.97it/s]\u001b[A\n",
            " 86% 24/28 [00:04<00:00,  4.96it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.96it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  4.97it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  4.98it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  4.98it/s]\n",
            "save trained model to /content/LoRA/output/hb_pro/hb_pro.safetensors\n",
            "model saved.\n",
            "steps: 100% 180/180 [05:10<00:00,  1.73s/it, loss=0.119]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PE3ES-oiVkk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LoRA/output/hb_pro/目录下的safetensor文件就是我们得到的LoRA模型，下载到WebUI就可以直接使用。"
      ],
      "metadata": {
        "id": "-lW9BqxjCHjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "试试推理？"
      ],
      "metadata": {
        "id": "C9v0773zVlDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "network_weight = \"/content/LoRA/output/hb_pro/hb_pro.safetensors\"\n",
        "network_mul = 1\n",
        "network_module = \"networks.lora\"\n",
        "network_args = \"\"\n",
        "\n",
        "v2 = False\n",
        "v_parameterization = False\n",
        "prompt = \"a woman with green t-shirt, smiling\"   # 你要测试的prompt\n",
        "negative = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\"\n",
        "model = pretrained_model_name_or_path\n",
        "vae = \"\"\n",
        "outdir = \"/content/tmp\"  # 图片存储的路径\n",
        "scale = 7\n",
        "sampler = \"euler_a\"\n",
        "steps = 20\n",
        "precision = \"fp16\"\n",
        "width = 512\n",
        "height = 512\n",
        "images_per_prompt = 4\n",
        "batch_size = 4\n",
        "clip_skip = 2\n",
        "seed = 1024\n",
        "\n",
        "final_prompt = f\"{prompt} --n {negative}\"\n",
        "\n",
        "config = {\n",
        "    \"v2\": v2,\n",
        "    \"v_parameterization\": v_parameterization,\n",
        "    \"network_module\": network_module,\n",
        "    \"network_weight\": network_weight,\n",
        "    \"network_mul\": float(network_mul),\n",
        "    \"network_args\": eval(network_args) if network_args else None,\n",
        "    \"ckpt\": model,\n",
        "    \"outdir\": outdir,\n",
        "    \"xformers\": True,\n",
        "    \"vae\": vae if vae else None,\n",
        "    \"fp16\": True,\n",
        "    \"W\": width,\n",
        "    \"H\": height,\n",
        "    \"seed\": seed if seed > 0 else None,\n",
        "    \"scale\": scale,\n",
        "    \"sampler\": sampler,\n",
        "    \"steps\": steps,\n",
        "    \"max_embeddings_multiples\": 3,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"images_per_prompt\": images_per_prompt,\n",
        "    \"clip_skip\": clip_skip if not v2 else None,\n",
        "    \"prompt\": final_prompt,\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python gen_img_diffusers.py {args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMetKpLVNr79",
        "outputId": "5e86bedb-bfd3-475e-8d76-8af4bb6c5c91"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load StableDiffusion checkpoint\n",
            "loading u-net: <All keys matched successfully>\n",
            "loading vae: <All keys matched successfully>\n",
            "loading text encoder: <All keys matched successfully>\n",
            "Replace CrossAttention.forward to use NAI style Hypernetwork and xformers\n",
            "loading tokenizer\n",
            "prepare tokenizer\n",
            "import network module: networks.lora\n",
            "load network weights from: /content/LoRA/output/hb_pro/hb_pro-000007.safetensors\n",
            "create LoRA network from weights\n",
            "create LoRA for Text Encoder: 72 modules.\n",
            "create LoRA for U-Net: 192 modules.\n",
            "enable LoRA for text encoder\n",
            "enable LoRA for U-Net\n",
            "weights are loaded: <All keys matched successfully>\n",
            "pipeline is ready.\n",
            "iteration 1/1\n",
            "prompt 1/1: a woman with green t-shirt, smiling\n",
            "negative prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\n",
            "100% 20/20 [00:15<00:00,  1.26it/s]\n",
            "done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "点开这个路径：/content/tmp，查看你生成的图片！可以更换代码里的prompt反复尝试几次。权重和图片记得保存本地，不然colab断开就都没了。"
      ],
      "metadata": {
        "id": "Ol9_GsBhDRHI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HlC1R3oIWSMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在你的WebUI里面玩起来？\n",
        "- 配合LoRA风格模型\n",
        "- 配合不同基础模型\n",
        "- 配合超分模块\n",
        "- 配合不同的prompt"
      ],
      "metadata": {
        "id": "7_5i8GPiWUQT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GdoQU998ExBv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}