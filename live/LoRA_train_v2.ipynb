{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKOaHmxB8YMX",
        "outputId": "3210e2ea-ab40-4d5d-c5be-0752cc0f5d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Aug  2 10:30:04 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    13W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# 检查GPU环境。如提示无GPU，需要点击「修改」-「笔记本设置」-「GPU-T4」，然后点击右上角的连接按键。\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入需要用到的Python工具包\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import time\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "u-kNF_oKA32P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置项目需要的各种路径，比如基础模型存放路径、LoRA模型训练后的存放路径等\n",
        "root_dir = os.path.abspath(\"/content\")\n",
        "deps_dir = os.path.join(root_dir, \"deps\")\n",
        "repo_dir = os.path.join(root_dir, \"kohya-trainer\")\n",
        "training_dir = os.path.join(root_dir, \"LoRA\")\n",
        "pretrained_model = os.path.join(root_dir, \"pretrained_model\")\n",
        "vae_dir = os.path.join(root_dir, \"vae\")\n",
        "config_dir = os.path.join(training_dir, \"config\")\n",
        "\n",
        "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "tools_dir = os.path.join(repo_dir, \"tools\")\n",
        "finetune_dir = os.path.join(repo_dir, \"finetune\")\n",
        "\n",
        "# TODO：在新的notebook中，这段代码可以删除\n",
        "for store in [\n",
        "    \"root_dir\",\n",
        "    \"deps_dir\",\n",
        "    \"repo_dir\",\n",
        "    \"training_dir\",\n",
        "    \"pretrained_model\",\n",
        "    \"vae_dir\",\n",
        "    \"accelerate_config\",\n",
        "    \"tools_dir\",\n",
        "    \"finetune_dir\",\n",
        "    \"config_dir\",\n",
        "]:\n",
        "    with capture.capture_output() as cap:\n",
        "        del cap"
      ],
      "metadata": {
        "id": "1Kd7tyYH80PG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "安装基础环境"
      ],
      "metadata": {
        "id": "tnHUIBth9RzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo_url = \"https://github.com/Linaqruf/kohya-trainer\"\n",
        "bitsandytes_main_py = \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py\"\n",
        "branch = \"\"\n",
        "install_xformers = True\n",
        "verbose = False\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "\n",
        "def clone_repo(url):\n",
        "    if not os.path.exists(repo_dir):\n",
        "        os.chdir(root_dir)\n",
        "        !git clone {url} {repo_dir}\n",
        "    else:\n",
        "        os.chdir(repo_dir)\n",
        "        !git pull origin {branch} if branch else !git pull\n",
        "\n",
        "\n",
        "def install_dependencies():\n",
        "    s = getoutput('nvidia-smi')\n",
        "\n",
        "    !pip install {'-q' if not verbose else ''} --upgrade -r requirements.txt\n",
        "    !pip install {'-q' if not verbose else ''} torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchaudio==2.0.1+cu118 torchtext==0.15.1 torchdata==0.6.0 --extra-index-url https://download.pytorch.org/whl/cu118 -U\n",
        "\n",
        "    if install_xformers:\n",
        "        !pip install {'-q' if not verbose else ''} xformers==0.0.19 triton==2.0.0 -U\n",
        "\n",
        "    from accelerate.utils import write_basic_config\n",
        "\n",
        "    if not os.path.exists(accelerate_config):\n",
        "        write_basic_config(save_location=accelerate_config)\n",
        "\n",
        "\n",
        "def main():\n",
        "    os.chdir(root_dir)\n",
        "\n",
        "    for dir in [\n",
        "        deps_dir,\n",
        "        training_dir,\n",
        "        config_dir,\n",
        "        pretrained_model,\n",
        "        vae_dir\n",
        "    ]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "    clone_repo(repo_url)\n",
        "\n",
        "    os.chdir(repo_dir)\n",
        "    !apt --fix-broken install\n",
        "    !apt install aria2 {'-qq' if not verbose else ''}\n",
        "\n",
        "    install_dependencies()\n",
        "    time.sleep(3)\n",
        "\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "\n",
        "    cuda_path = \"/usr/local/cuda-11.8/targets/x86_64-linux/lib/\"\n",
        "    ld_library_path = os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
        "    os.environ[\"LD_LIBRARY_PATH\"] = f\"{ld_library_path}:{cuda_path}\"\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOH4vjKo9Bru",
        "outputId": "68e51dbe-ef9d-4e9d-f0ba-0228d631b845"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/kohya-trainer'...\n",
            "remote: Enumerating objects: 2481, done.\u001b[K\n",
            "remote: Counting objects: 100% (1149/1149), done.\u001b[K\n",
            "remote: Compressing objects: 100% (369/369), done.\u001b[K\n",
            "remote: Total 2481 (delta 887), reused 919 (delta 780), pack-reused 1332\u001b[K\n",
            "Receiving objects: 100% (2481/2481), 4.91 MiB | 852.00 KiB/s, done.\n",
            "Resolving deltas: 100% (1642/1642), done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 1,513 kB of archives.\n",
            "After this operation, 5,441 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 120500 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.1/503.1 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.8/599.8 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m729.2/729.2 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.0/115.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dadaptation (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for library (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for elfinder-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m626.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.2/108.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "下载基础模型"
      ],
      "metadata": {
        "id": "3AN0e9gf-L-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 下面提供了一些模型的下载链接，你可以到Hugging Face和CivitAI上获取更多模型。\n",
        "\n",
        "# \"Anything-v3-1\": \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\",\n",
        "# \"AnyLoRA\": \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/AnyLoRA_noVae_fp16-pruned.safetensors\",\n",
        "# \"AnyLoRA-anime-mix\": \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AAM_Anylora_AnimeMix.safetensors\",\n",
        "# \"AnimePastelDream\": \"https://huggingface.co/Lykon/AnimePastelDream/resolve/main/AnimePastelDream_Soft_noVae_fp16.safetensors\",\n",
        "# \"Chillout-mix\": \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/chillout_mix-pruned.safetensors\",\n",
        "# \"OpenJourney-v4\": \"https://huggingface.co/prompthero/openjourney-v4/resolve/main/openjourney-v4.ckpt\",\n",
        "# \"Stable-Diffusion-v1-5\": \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors\""
      ],
      "metadata": {
        "id": "YR74ThL19Z1Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 下载你要用的基础模型。这些我用的是AnyLoRA基础模型，你可以根据喜欢进行更换。\n",
        "# 真人风格推荐用Chillout-mix 这类模型\n",
        "# 卡通风格推荐AnyLoRA、Anything这类模型\n",
        "# pretrained_model_name_or_path = \"/content/pretrained_model/AnyLoRA_noVae_fp16-pruned.safetensors\"\n",
        "# !wget -c https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/AnyLoRA_noVae_fp16-pruned.safetensors -O $pretrained_model_name_or_path\n",
        "\n",
        "pretrained_model_name_or_path = \"/content/pretrained_model/moyou.safetensors\"\n",
        "!wget -c https://huggingface.co/wind1/MoYou/resolve/main/%E9%99%90%E6%97%B6%E7%8B%AC%E5%8D%A0%EF%B8%B1%E5%A2%A8%E5%B9%BD%E4%BA%BA%E9%80%A0%E4%BA%BA_v1010%E5%AE%8C%E6%95%B4.safetensors -O $pretrained_model_name_or_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDArHtcG-ZyZ",
        "outputId": "f4bc287f-0c68-4f3d-c383-2ae29552494f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-02 10:34:07--  https://huggingface.co/wind1/MoYou/resolve/main/%E9%99%90%E6%97%B6%E7%8B%AC%E5%8D%A0%EF%B8%B1%E5%A2%A8%E5%B9%BD%E4%BA%BA%E9%80%A0%E4%BA%BA_v1010%E5%AE%8C%E6%95%B4.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 52.84.162.49, 52.84.162.101, 52.84.162.22, ...\n",
            "Connecting to huggingface.co (huggingface.co)|52.84.162.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/c8/3c/c83ce79715db76543fa20d1d6c44c50e979b06f456884dab974eccc49543ad99/6a226dd292a983b3ed4987402453ad4d954b77825c1cf99d39d8746909791761?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27%25E9%2599%2590%25E6%2597%25B6%25E7%258B%25AC%25E5%258D%25A0%25EF%25B8%25B1%25E5%25A2%25A8%25E5%25B9%25BD%25E4%25BA%25BA%25E9%2580%25A0%25E4%25BA%25BA_v1010%25E5%25AE%258C%25E6%2595%25B4.safetensors%3B+filename%3D%22%C3%A9%C2%99%C2%90%C3%A6%C2%97%C2%B6%C3%A7%C2%8B%C2%AC%C3%A5%C2%8D%C2%A0%C3%AF%C2%B8%C2%B1%C3%A5%C2%A2%C2%A8%C3%A5%C2%B9%C2%BD%C3%A4%C2%BA%C2%BA%C3%A9%C2%80%C2%A0%C3%A4%C2%BA%C2%BA_v1010%C3%A5%C2%AE%C2%8C%C3%A6%C2%95%C2%B4.safetensors%22%3B&Expires=1691231647&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MTIzMTY0N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9jOC8zYy9jODNjZTc5NzE1ZGI3NjU0M2ZhMjBkMWQ2YzQ0YzUwZTk3OWIwNmY0NTY4ODRkYWI5NzRlY2NjNDk1NDNhZDk5LzZhMjI2ZGQyOTJhOTgzYjNlZDQ5ODc0MDI0NTNhZDRkOTU0Yjc3ODI1YzFjZjk5ZDM5ZDg3NDY5MDk3OTE3NjE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=J%7E1-JbGqyXmeqjftDVFmj%7EoRR1D6XMA3juqdOsnuBIfCQ61Mc9koRhK1%7EfjrzVfLR57JbqeLhHgiXHLqI4W90CI6xXr4H-ZiOHJ4kUtO5lIcca%7ElkEbdbbhzy0lixHluRE-0X4d0AJ1%7EwO7-rl1EOGgtoV3Ul-vKDROJuU0jpzK-W%7E324h7VviH8i7ga5NHZwsHDbLYOYxiytpn8dtlt5YuIsLqwRxVekqIKf-wtUUavSmBSA%7EzV8ChqITJyiyChrZrUbaW0fbFym-GKm7UtYXssZfPHRQ0BvyBL4E92Ba4pzWj82NNxNcHfGihUnIcdawS-B0eLhtT41rnjS12FYg__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-08-02 10:34:07--  https://cdn-lfs.huggingface.co/repos/c8/3c/c83ce79715db76543fa20d1d6c44c50e979b06f456884dab974eccc49543ad99/6a226dd292a983b3ed4987402453ad4d954b77825c1cf99d39d8746909791761?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27%25E9%2599%2590%25E6%2597%25B6%25E7%258B%25AC%25E5%258D%25A0%25EF%25B8%25B1%25E5%25A2%25A8%25E5%25B9%25BD%25E4%25BA%25BA%25E9%2580%25A0%25E4%25BA%25BA_v1010%25E5%25AE%258C%25E6%2595%25B4.safetensors%3B+filename%3D%22%C3%A9%C2%99%C2%90%C3%A6%C2%97%C2%B6%C3%A7%C2%8B%C2%AC%C3%A5%C2%8D%C2%A0%C3%AF%C2%B8%C2%B1%C3%A5%C2%A2%C2%A8%C3%A5%C2%B9%C2%BD%C3%A4%C2%BA%C2%BA%C3%A9%C2%80%C2%A0%C3%A4%C2%BA%C2%BA_v1010%C3%A5%C2%AE%C2%8C%C3%A6%C2%95%C2%B4.safetensors%22%3B&Expires=1691231647&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MTIzMTY0N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9jOC8zYy9jODNjZTc5NzE1ZGI3NjU0M2ZhMjBkMWQ2YzQ0YzUwZTk3OWIwNmY0NTY4ODRkYWI5NzRlY2NjNDk1NDNhZDk5LzZhMjI2ZGQyOTJhOTgzYjNlZDQ5ODc0MDI0NTNhZDRkOTU0Yjc3ODI1YzFjZjk5ZDM5ZDg3NDY5MDk3OTE3NjE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=J%7E1-JbGqyXmeqjftDVFmj%7EoRR1D6XMA3juqdOsnuBIfCQ61Mc9koRhK1%7EfjrzVfLR57JbqeLhHgiXHLqI4W90CI6xXr4H-ZiOHJ4kUtO5lIcca%7ElkEbdbbhzy0lixHluRE-0X4d0AJ1%7EwO7-rl1EOGgtoV3Ul-vKDROJuU0jpzK-W%7E324h7VviH8i7ga5NHZwsHDbLYOYxiytpn8dtlt5YuIsLqwRxVekqIKf-wtUUavSmBSA%7EzV8ChqITJyiyChrZrUbaW0fbFym-GKm7UtYXssZfPHRQ0BvyBL4E92Ba4pzWj82NNxNcHfGihUnIcdawS-B0eLhtT41rnjS12FYg__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.65.229.35, 18.65.229.83, 18.65.229.16, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.65.229.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7812594334 (7.3G) [binary/octet-stream]\n",
            "Saving to: ‘/content/pretrained_model/moyou.safetensors’\n",
            "\n",
            "/content/pretrained 100%[===================>]   7.28G  48.8MB/s    in 2m 48s  \n",
            "\n",
            "2023-08-02 10:36:55 (44.4 MB/s) - ‘/content/pretrained_model/moyou.safetensors’ saved [7812594334/7812594334]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "准备数据"
      ],
      "metadata": {
        "id": "dwbHq_3k-ri1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = os.path.join(root_dir, \"LoRA/train_data/hb_cartoon\")\n",
        "os.makedirs(train_data_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Your train data directory : {train_data_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa4sdqtY-i6G",
        "outputId": "7ffc444c-5951-4745-90f2-b2e43c618bfe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your train data directory : /content/LoRA/train_data/hb_cartoon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 如果使用提前准备的赫本图片，可以执行下面这段代码\n",
        "# 如果你想使用自己的图片训练LoRA，可以将你的图片上传到/content/LoRA/train_data/hb_cartoon 路径下，跳过这段代码。\n",
        "\n",
        "import os\n",
        "if not os.path.isdir(\"ai_painting_journey\"):\n",
        "  !git clone https://github.com/NightWalker888/ai_painting_journey.git\n",
        "\n",
        "if not os.listdir(\"/content/LoRA/train_data/hb_cartoon\"):\n",
        "  !tar -xvf ai_painting_journey/live/herburn_images.tar -C /content/LoRA/train_data/\n",
        "\n",
        "train_data_dir = os.path.join(root_dir, \"LoRA/train_data/herburn_images\")"
      ],
      "metadata": {
        "id": "T7ChUFh_GDoI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6893e947-f831-4149-ec66-df68955f88b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ai_painting_journey'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 33 (delta 8), reused 28 (delta 5), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (33/33), 10.56 MiB | 19.25 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "herburn_images/\n",
            "herburn_images/._herben_cartoon16.png\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
            "herburn_images/herben_cartoon16.png\n",
            "herburn_images/._heben1.jpg\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.metadata:kMDItemWhereFroms'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
            "herburn_images/heben1.jpg\n",
            "herburn_images/._heben3.jpg\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.metadata:kMDItemWhereFroms'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
            "herburn_images/heben3.jpg\n",
            "herburn_images/._herben_cartoon4.png\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
            "herburn_images/herben_cartoon4.png\n",
            "herburn_images/._heben6.jpg\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.metadata:kMDItemScreenCaptureType'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.metadata:kMDItemScreenCaptureGlobalRect'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.metadata:kMDItemIsScreenCapture'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.lastuseddate#PS'\n",
            "herburn_images/heben6.jpg\n",
            "herburn_images/._heben4.jpg\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.metadata:kMDItemScreenCaptureType'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.metadata:kMDItemScreenCaptureGlobalRect'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.metadata:kMDItemIsScreenCapture'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.lastuseddate#PS'\n",
            "herburn_images/heben4.jpg\n",
            "herburn_images/._heben19.jpg\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.metadata:kMDItemWhereFroms'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
            "herburn_images/heben19.jpg\n",
            "herburn_images/._herben_cartoon8.png\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
            "herburn_images/herben_cartoon8.png\n",
            "herburn_images/._herben_cartoon20.png\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
            "herburn_images/herben_cartoon20.png\n",
            "herburn_images/._herben_cartoon24.png\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
            "herburn_images/herben_cartoon24.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **操作说明: 需要将你准备的照片放置在上面的路径下，比如这里的路径是：/content/LoRA/train_data/hb_cartoon。直接将图片拖到文件夹中就行！确保文件上传完成后，到下一步。10图以上，多少随意。**"
      ],
      "metadata": {
        "id": "-7xlSQ92_3Wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用BLIP模型给你的图片加上prompt，用于训练。\n",
        "# BLIP是一个多模态生成算法，输入图片，得到图片的prompt描述信息。\n",
        "\n",
        "import os\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "\n",
        "batch_size = 8\n",
        "max_data_loader_n_workers = 2\n",
        "beam_search = True\n",
        "min_length = 5\n",
        "max_length = 75\n",
        "recursive = False\n",
        "verbose_logging = True\n",
        "\n",
        "config = {\n",
        "    \"_train_data_dir\" : train_data_dir,\n",
        "    \"batch_size\" : batch_size,\n",
        "    \"beam_search\" : beam_search,\n",
        "    \"min_length\" : min_length,\n",
        "    \"max_length\" : max_length,\n",
        "    \"debug\" : verbose_logging,\n",
        "    \"caption_extension\" : \".caption\",\n",
        "    \"max_data_loader_n_workers\" : max_data_loader_n_workers,\n",
        "    \"recursive\" : recursive\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python make_captions.py {args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{final_args}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bKEjOIe-0Sj",
        "outputId": "6d8bfcbd-ee25-4b69-e50e-12f598077e7a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load images from /content/LoRA/train_data/herburn_images\n",
            "found 20 images.\n",
            "loading BLIP caption: https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 3.33MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 170kB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 570/570 [00:00<00:00, 3.31MB/s]\n",
            "100% 1.66G/1.66G [00:07<00:00, 240MB/s]\n",
            "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "BLIP loaded\n",
            "  0% 0/3 [00:00<?, ?it/s]Could not load image path / 画像を読み込めません: /content/LoRA/train_data/herburn_images/._herben_cartoon4.png, error: cannot identify image file '/content/LoRA/train_data/herburn_images/._herben_cartoon4.png'\n",
            "Could not load image path / 画像を読み込めません: /content/LoRA/train_data/herburn_images/._heben1.jpg, error: cannot identify image file '/content/LoRA/train_data/herburn_images/._heben1.jpg'\n",
            "Could not load image path / 画像を読み込めません: /content/LoRA/train_data/herburn_images/._heben19.jpg, error: cannot identify image file '/content/LoRA/train_data/herburn_images/._heben19.jpg'\n",
            "Could not load image path / 画像を読み込めません: /content/LoRA/train_data/herburn_images/._herben_cartoon8.png, error: cannot identify image file '/content/LoRA/train_data/herburn_images/._herben_cartoon8.png'\n",
            "Could not load image path / 画像を読み込めません: /content/LoRA/train_data/herburn_images/._heben3.jpg, error: cannot identify image file '/content/LoRA/train_data/herburn_images/._heben3.jpg'\n",
            "Could not load image path / 画像を読み込めません: /content/LoRA/train_data/herburn_images/._heben4.jpg, error: cannot identify image file '/content/LoRA/train_data/herburn_images/._heben4.jpg'\n",
            "Could not load image path / 画像を読み込めません: /content/LoRA/train_data/herburn_images/._heben6.jpg, error: cannot identify image file '/content/LoRA/train_data/herburn_images/._heben6.jpg'\n",
            "Could not load image path / 画像を読み込めません: /content/LoRA/train_data/herburn_images/._herben_cartoon16.png, error: cannot identify image file '/content/LoRA/train_data/herburn_images/._herben_cartoon16.png'\n",
            "Could not load image path / 画像を読み込めません: /content/LoRA/train_data/herburn_images/._herben_cartoon20.png, error: cannot identify image file '/content/LoRA/train_data/herburn_images/._herben_cartoon20.png'\n",
            "Could not load image path / 画像を読み込めません: /content/LoRA/train_data/herburn_images/._herben_cartoon24.png, error: cannot identify image file '/content/LoRA/train_data/herburn_images/._herben_cartoon24.png'\n",
            " 67% 2/3 [00:00<00:00,  3.50it/s]/content/LoRA/train_data/herburn_images/heben1.jpg a woman with a purple shirt and red lipstick\n",
            "/content/LoRA/train_data/herburn_images/heben19.jpg a woman in a white dress with her arms crossed\n",
            "/content/LoRA/train_data/herburn_images/heben3.jpg a woman in a red jacket with a poodle on it\n",
            "/content/LoRA/train_data/herburn_images/heben4.jpg a woman with a black dress and earrings\n",
            "/content/LoRA/train_data/herburn_images/heben6.jpg a woman in a white dress and gloves\n",
            "/content/LoRA/train_data/herburn_images/herben_cartoon16.png a woman with a flower in her hair\n",
            "/content/LoRA/train_data/herburn_images/herben_cartoon20.png a woman with a pearl necklace and earrings\n",
            "/content/LoRA/train_data/herburn_images/herben_cartoon24.png a girl with a flower in her hair\n",
            "100% 3/3 [00:10<00:00,  3.47s/it]\n",
            "/content/LoRA/train_data/herburn_images/herben_cartoon4.png a woman with a pink bow on her neck\n",
            "/content/LoRA/train_data/herburn_images/herben_cartoon8.png a woman with a hat and a white shirt\n",
            "done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "训练配置"
      ],
      "metadata": {
        "id": "H-oNLmEyMic3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_name = \"hb_pro\"\n",
        "vae = \"\" # 使用基础模型中的VAE\n",
        "output_dir = os.path.join(root_dir, \"LoRA/output/hb_pro\")\n",
        "\n",
        "sample_dir = os.path.join(output_dir, \"sample\")\n",
        "for dir in [output_dir, sample_dir]:\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "print(\"Project Name: \", project_name)\n",
        "print(\n",
        "    \"Pretrained Model Path: \", pretrained_model_name_or_path\n",
        ") if pretrained_model_name_or_path else print(\"No Pretrained Model path specified.\")\n",
        "\n",
        "print(\"VAE Path: \", vae) if vae else print(\"No VAE path specified.\")\n",
        "print(\"Output Path: \", output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMv2gmZZMg-C",
        "outputId": "83cc8f16-0467-4b2d-f555-2ca77cb8dc6d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project Name:  hb_pro\n",
            "Pretrained Model Path:  /content/pretrained_model/moyou.safetensors\n",
            "No VAE path specified.\n",
            "Output Path:  /content/LoRA/output/hb_pro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 这段代码用于预处理数据，将我们的训练数据、正则化数据处理成训练模型能用的dataloader\n",
        "# 数据增广是非常关键的操作，比如图像翻转、图像颜色扰动、图像朝着目标风格的迁移等。这些都是后期可调的。\n",
        "\n",
        "import os\n",
        "import toml\n",
        "import glob\n",
        "\n",
        "dataset_repeats = 20\n",
        "activation_word = \"\"\n",
        "caption_extension = \".caption\"\n",
        "resolution = 512\n",
        "flip_aug = True\n",
        "keep_tokens = 0\n",
        "\n",
        "def parse_folder_name(folder_name, default_num_repeats, default_class_token):\n",
        "    folder_name_parts = folder_name.split(\"_\")\n",
        "\n",
        "    if len(folder_name_parts) == 2:\n",
        "        if folder_name_parts[0].isdigit():\n",
        "            num_repeats = int(folder_name_parts[0])\n",
        "            class_token = folder_name_parts[1].replace(\"_\", \" \")\n",
        "        else:\n",
        "            num_repeats = default_num_repeats\n",
        "            class_token = default_class_token\n",
        "    else:\n",
        "        num_repeats = default_num_repeats\n",
        "        class_token = default_class_token\n",
        "\n",
        "    return num_repeats, class_token\n",
        "\n",
        "def find_image_files(path):\n",
        "    supported_extensions = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")\n",
        "    return [file for file in glob.glob(path + '/**/*', recursive=True) if file.lower().endswith(supported_extensions)]\n",
        "\n",
        "def process_data_dir(data_dir, default_num_repeats, default_class_token, is_reg=False):\n",
        "    subsets = []\n",
        "\n",
        "    images = find_image_files(data_dir)\n",
        "    if images:\n",
        "        subsets.append({\n",
        "            \"image_dir\": data_dir,\n",
        "            \"class_tokens\": default_class_token,\n",
        "            \"num_repeats\": default_num_repeats,\n",
        "            **({\"is_reg\": is_reg} if is_reg else {}),\n",
        "        })\n",
        "\n",
        "    for root, dirs, files in os.walk(data_dir):\n",
        "        for folder in dirs:\n",
        "            folder_path = os.path.join(root, folder)\n",
        "            images = find_image_files(folder_path)\n",
        "\n",
        "            if images:\n",
        "                num_repeats, class_token = parse_folder_name(folder, default_num_repeats, default_class_token)\n",
        "\n",
        "                subset = {\n",
        "                    \"image_dir\": folder_path,\n",
        "                    \"class_tokens\": class_token,\n",
        "                    \"num_repeats\": num_repeats,\n",
        "                }\n",
        "\n",
        "                if is_reg:\n",
        "                    subset[\"is_reg\"] = True\n",
        "\n",
        "                subsets.append(subset)\n",
        "\n",
        "    return subsets\n",
        "\n",
        "\n",
        "train_subsets = process_data_dir(train_data_dir, dataset_repeats, activation_word)\n",
        "print(train_subsets)\n",
        "# reg_subsets = process_data_dir(reg_data_dir, dataset_repeats, activation_word, is_reg=True)\n",
        "\n",
        "# subsets = train_subsets + reg_subsets\n",
        "subsets = train_subsets\n",
        "\n",
        "config = {\n",
        "    \"general\": {\n",
        "        \"enable_bucket\": True,\n",
        "        \"caption_extension\": caption_extension,\n",
        "        \"shuffle_caption\": True,\n",
        "        \"keep_tokens\": keep_tokens,\n",
        "        \"bucket_reso_steps\": 64,\n",
        "        \"bucket_no_upscale\": False,\n",
        "    },\n",
        "    \"datasets\": [\n",
        "        {\n",
        "            \"resolution\": resolution,\n",
        "            \"min_bucket_reso\": 320 if resolution > 640 else 256,\n",
        "            \"max_bucket_reso\": 1280 if resolution > 640 else 1024,\n",
        "            \"caption_dropout_rate\": 0,\n",
        "            \"caption_tag_dropout_rate\": 0,\n",
        "            \"caption_dropout_every_n_epochs\": 0,\n",
        "            \"flip_aug\": flip_aug,\n",
        "            \"color_aug\": False,\n",
        "            \"face_crop_aug_range\": None,\n",
        "            \"subsets\": subsets,\n",
        "        }\n",
        "    ],\n",
        "}\n",
        "\n",
        "dataset_config = os.path.join(config_dir, \"dataset_config.toml\")\n",
        "\n",
        "for key in config:\n",
        "    if isinstance(config[key], dict):\n",
        "        for sub_key in config[key]:\n",
        "            if config[key][sub_key] == \"\":\n",
        "                config[key][sub_key] = None\n",
        "    elif config[key] == \"\":\n",
        "        config[key] = None\n",
        "\n",
        "config_str = toml.dumps(config)\n",
        "\n",
        "with open(dataset_config, \"w\") as f:\n",
        "    f.write(config_str)\n",
        "\n",
        "print(config_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90LnMgMD_QOO",
        "outputId": "453fb084-6641-493f-c5b7-6c89c9e4012e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'image_dir': '/content/LoRA/train_data/herburn_images', 'class_tokens': '', 'num_repeats': 20}]\n",
            "[[datasets]]\n",
            "resolution = 512\n",
            "min_bucket_reso = 256\n",
            "max_bucket_reso = 1024\n",
            "caption_dropout_rate = 0\n",
            "caption_tag_dropout_rate = 0\n",
            "caption_dropout_every_n_epochs = 0\n",
            "flip_aug = true\n",
            "color_aug = false\n",
            "[[datasets.subsets]]\n",
            "image_dir = \"/content/LoRA/train_data/herburn_images\"\n",
            "class_tokens = \"\"\n",
            "num_repeats = 20\n",
            "\n",
            "\n",
            "[general]\n",
            "enable_bucket = true\n",
            "caption_extension = \".caption\"\n",
            "shuffle_caption = true\n",
            "keep_tokens = 0\n",
            "bucket_reso_steps = 64\n",
            "bucket_no_upscale = false\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 可以提供预训练的LoRA模型\n",
        "# 分别设置text_encoder和UNet的学习率\n",
        "\n",
        "network_category = \"LoRA\"\n",
        "\n",
        "conv_dim = 32\n",
        "conv_alpha = 16\n",
        "network_dim = 32\n",
        "network_alpha = 16\n",
        "network_weight = \"\"\n",
        "network_module = \"networks.lora\"\n",
        "network_args = \"\"\n",
        "\n",
        "min_snr_gamma = -1\n",
        "optimizer_type = \"AdamW8bit\"\n",
        "optimizer_args = \"\"\n",
        "train_unet = True\n",
        "unet_lr = 1e-4\n",
        "train_text_encoder = True\n",
        "text_encoder_lr = 5e-5\n",
        "lr_scheduler = \"constant\"\n",
        "lr_warmup_steps = 0\n",
        "lr_scheduler_num_cycles = 0\n",
        "lr_scheduler_power = 0\n",
        "\n",
        "print(\"- LoRA Config:\")\n",
        "print(f\"  - Min-SNR Weighting: {min_snr_gamma}\") if not min_snr_gamma == -1 else \"\"\n",
        "print(f\"  - Loading network module: {network_module}\")\n",
        "print(f\"  - {network_module} linear_dim set to: {network_dim}\")\n",
        "print(f\"  - {network_module} linear_alpha set to: {network_alpha}\")\n",
        "\n",
        "if not network_weight:\n",
        "    print(\"  - No LoRA weight loaded.\")\n",
        "else:\n",
        "    if os.path.exists(network_weight):\n",
        "        print(f\"  - Loading LoRA weight: {network_weight}\")\n",
        "    else:\n",
        "        print(f\"  - {network_weight} does not exist.\")\n",
        "        network_weight = \"\"\n",
        "\n",
        "print(\"- Optimizer Config:\")\n",
        "print(f\"  - Additional network category: {network_category}\")\n",
        "print(f\"  - Using {optimizer_type} as Optimizer\")\n",
        "if optimizer_args:\n",
        "    print(f\"  - Optimizer Args: {optimizer_args}\")\n",
        "if train_unet and train_text_encoder:\n",
        "    print(\"  - Train UNet and Text Encoder\")\n",
        "    print(f\"    - UNet learning rate: {unet_lr}\")\n",
        "    print(f\"    - Text encoder learning rate: {text_encoder_lr}\")\n",
        "if train_unet and not train_text_encoder:\n",
        "    print(\"  - Train UNet only\")\n",
        "    print(f\"    - UNet learning rate: {unet_lr}\")\n",
        "if train_text_encoder and not train_unet:\n",
        "    print(\"  - Train Text Encoder only\")\n",
        "    print(f\"    - Text encoder learning rate: {text_encoder_lr}\")\n",
        "print(f\"  - Learning rate warmup steps: {lr_warmup_steps}\")\n",
        "print(f\"  - Learning rate Scheduler: {lr_scheduler}\")\n",
        "if lr_scheduler == \"cosine_with_restarts\":\n",
        "    print(f\"  - lr_scheduler_num_cycles: {lr_scheduler_num_cycles}\")\n",
        "elif lr_scheduler == \"polynomial\":\n",
        "    print(f\"  - lr_scheduler_power: {lr_scheduler_power}\")"
      ],
      "metadata": {
        "id": "NSf_JvU6_0Lk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da41c02-e6e2-4f4d-86eb-81ef0433eeb0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- LoRA Config:\n",
            "  - Loading network module: networks.lora\n",
            "  - networks.lora linear_dim set to: 32\n",
            "  - networks.lora linear_alpha set to: 16\n",
            "  - No LoRA weight loaded.\n",
            "- Optimizer Config:\n",
            "  - Additional network category: LoRA\n",
            "  - Using AdamW8bit as Optimizer\n",
            "  - Train UNet and Text Encoder\n",
            "    - UNet learning rate: 0.0001\n",
            "    - Text encoder learning rate: 5e-05\n",
            "  - Learning rate warmup steps: 0\n",
            "  - Learning rate Scheduler: constant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置存储模型的格式，我们为了适配WebUI，使用safetensors格式\n",
        "# 设置测试用prompt\n",
        "# 设置训练参数\n",
        "\n",
        "\n",
        "import toml\n",
        "import os\n",
        "\n",
        "lowram = True\n",
        "enable_sample_prompt = True\n",
        "sampler = \"ddim\"  #[\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "noise_offset = 0.0\n",
        "num_epochs = 10\n",
        "vae_batch_size = 4\n",
        "train_batch_size = 6\n",
        "mixed_precision = \"fp16\"  # [\"no\",\"fp16\",\"bf16\"]\n",
        "save_precision = \"fp16\"  #  [\"float\", \"fp16\", \"bf16\"]\n",
        "save_n_epochs_type = \"save_every_n_epochs\"\n",
        "save_n_epochs_type_value = 1\n",
        "save_model_as = \"safetensors\"  # [\"ckpt\", \"pt\", \"safetensors\"]\n",
        "max_token_length = 225\n",
        "clip_skip = 2\n",
        "gradient_checkpointing = False\n",
        "gradient_accumulation_steps = 1\n",
        "seed = -1\n",
        "logging_dir = os.path.join(root_dir, \"LoRA/logs\")\n",
        "prior_loss_weight = 1.0\n",
        "os.chdir(repo_dir)\n",
        "\n",
        "# sample_str = f\"\"\"\n",
        "#   masterpiece, best quality, a woman with a very short haircut and a pink shirt, looking at viewer, simple background \\\n",
        "#   --n lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry \\\n",
        "#   --w 512 \\\n",
        "#   --h 512 \\\n",
        "#   --l 7 \\\n",
        "#   --s 28\n",
        "# \"\"\"\n",
        "\n",
        "sample_str = f\"\"\"\n",
        "  masterpiece, best quality, 1girl,moyou，very short haircut and a pink shirt, looking at viewer, simple background \\\n",
        "  --n EasyNegativeV2,(badhandv4:1.2), \\\n",
        "  --w 512 \\\n",
        "  --h 512 \\\n",
        "  --l 7 \\\n",
        "  --s 28\n",
        "\"\"\"\n",
        "\n",
        "config = {\n",
        "    \"model_arguments\": {\n",
        "        \"v2\": False,\n",
        "        \"v_parameterization\": False,\n",
        "        \"pretrained_model_name_or_path\": pretrained_model_name_or_path,\n",
        "        \"vae\": vae,\n",
        "    },\n",
        "    \"additional_network_arguments\": {\n",
        "        \"no_metadata\": False,\n",
        "        \"unet_lr\": float(unet_lr) if train_unet else None,\n",
        "        \"text_encoder_lr\": float(text_encoder_lr) if train_text_encoder else None,\n",
        "        \"network_weights\": network_weight,\n",
        "        \"network_module\": network_module,\n",
        "        \"network_dim\": network_dim,\n",
        "        \"network_alpha\": network_alpha,\n",
        "        \"network_args\": network_args,\n",
        "        \"network_train_unet_only\": True if train_unet and not train_text_encoder else False,\n",
        "        \"network_train_text_encoder_only\": True if train_text_encoder and not train_unet else False,\n",
        "        \"training_comment\": None,\n",
        "    },\n",
        "    \"optimizer_arguments\": {\n",
        "        \"min_snr_gamma\": min_snr_gamma if not min_snr_gamma == -1 else None,\n",
        "        \"optimizer_type\": optimizer_type,\n",
        "        \"learning_rate\": unet_lr,\n",
        "        \"max_grad_norm\": 1.0,\n",
        "        \"optimizer_args\": eval(optimizer_args) if optimizer_args else None,\n",
        "        \"lr_scheduler\": lr_scheduler,\n",
        "        \"lr_warmup_steps\": lr_warmup_steps,\n",
        "        \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles if lr_scheduler == \"cosine_with_restarts\" else None,\n",
        "        \"lr_scheduler_power\": lr_scheduler_power if lr_scheduler == \"polynomial\" else None,\n",
        "    },\n",
        "    \"dataset_arguments\": {\n",
        "        \"cache_latents\": True,\n",
        "        \"debug_dataset\": False,\n",
        "        \"vae_batch_size\": vae_batch_size,\n",
        "    },\n",
        "    \"training_arguments\": {\n",
        "        \"output_dir\": output_dir,\n",
        "        \"output_name\": project_name,\n",
        "        \"save_precision\": save_precision,\n",
        "        \"save_every_n_epochs\": save_n_epochs_type_value if save_n_epochs_type == \"save_every_n_epochs\" else None,\n",
        "        \"save_n_epoch_ratio\": save_n_epochs_type_value if save_n_epochs_type == \"save_n_epoch_ratio\" else None,\n",
        "        \"save_last_n_epochs\": None,\n",
        "        \"save_state\": None,\n",
        "        \"save_last_n_epochs_state\": None,\n",
        "        \"resume\": None,\n",
        "        \"train_batch_size\": train_batch_size,\n",
        "        \"max_token_length\": 225,\n",
        "        \"mem_eff_attn\": False,\n",
        "        \"xformers\": True,\n",
        "        \"max_train_epochs\": num_epochs,\n",
        "        \"max_data_loader_n_workers\": 8,\n",
        "        \"persistent_data_loader_workers\": True,\n",
        "        \"seed\": seed if seed > 0 else None,\n",
        "        \"gradient_checkpointing\": gradient_checkpointing,\n",
        "        \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
        "        \"mixed_precision\": mixed_precision,\n",
        "        \"clip_skip\": clip_skip,\n",
        "        \"logging_dir\": logging_dir,\n",
        "        \"log_prefix\": project_name,\n",
        "        \"noise_offset\": noise_offset if noise_offset > 0 else None,\n",
        "        \"lowram\": lowram,\n",
        "    },\n",
        "    \"sample_prompt_arguments\": {\n",
        "        \"sample_every_n_steps\": None,\n",
        "        \"sample_every_n_epochs\": 1 if enable_sample_prompt else 999999,\n",
        "        \"sample_sampler\": sampler,\n",
        "    },\n",
        "    \"dreambooth_arguments\": {\n",
        "        \"prior_loss_weight\": 1.0,\n",
        "    },\n",
        "    \"saving_arguments\": {\n",
        "        \"save_model_as\": save_model_as\n",
        "    },\n",
        "}\n",
        "\n",
        "config_path = os.path.join(config_dir, \"config_file.toml\")\n",
        "prompt_path = os.path.join(config_dir, \"sample_prompt.txt\")\n",
        "\n",
        "\n",
        "for key in config:\n",
        "    if isinstance(config[key], dict):\n",
        "        for sub_key in config[key]:\n",
        "            if config[key][sub_key] == \"\":\n",
        "                config[key][sub_key] = None\n",
        "    elif config[key] == \"\":\n",
        "        config[key] = None\n",
        "\n",
        "config_str = toml.dumps(config)\n",
        "\n",
        "write_file(config_path, config_str)\n",
        "write_file(prompt_path, sample_str)\n",
        "\n",
        "print(config_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCrsnXwvNHQp",
        "outputId": "c4296312-a2e3-4f7b-a79e-ecce2d1b2590"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[model_arguments]\n",
            "v2 = false\n",
            "v_parameterization = false\n",
            "pretrained_model_name_or_path = \"/content/pretrained_model/moyou.safetensors\"\n",
            "\n",
            "[additional_network_arguments]\n",
            "no_metadata = false\n",
            "unet_lr = 0.0001\n",
            "text_encoder_lr = 5e-5\n",
            "network_module = \"networks.lora\"\n",
            "network_dim = 32\n",
            "network_alpha = 16\n",
            "network_train_unet_only = false\n",
            "network_train_text_encoder_only = false\n",
            "\n",
            "[optimizer_arguments]\n",
            "optimizer_type = \"AdamW8bit\"\n",
            "learning_rate = 0.0001\n",
            "max_grad_norm = 1.0\n",
            "lr_scheduler = \"constant\"\n",
            "lr_warmup_steps = 0\n",
            "\n",
            "[dataset_arguments]\n",
            "cache_latents = true\n",
            "debug_dataset = false\n",
            "vae_batch_size = 4\n",
            "\n",
            "[training_arguments]\n",
            "output_dir = \"/content/LoRA/output/hb_pro\"\n",
            "output_name = \"hb_pro\"\n",
            "save_precision = \"fp16\"\n",
            "save_every_n_epochs = 1\n",
            "train_batch_size = 6\n",
            "max_token_length = 225\n",
            "mem_eff_attn = false\n",
            "xformers = true\n",
            "max_train_epochs = 10\n",
            "max_data_loader_n_workers = 8\n",
            "persistent_data_loader_workers = true\n",
            "gradient_checkpointing = false\n",
            "gradient_accumulation_steps = 1\n",
            "mixed_precision = \"fp16\"\n",
            "clip_skip = 2\n",
            "logging_dir = \"/content/LoRA/logs\"\n",
            "log_prefix = \"hb_pro\"\n",
            "lowram = true\n",
            "\n",
            "[sample_prompt_arguments]\n",
            "sample_every_n_epochs = 1\n",
            "sample_sampler = \"ddim\"\n",
            "\n",
            "[dreambooth_arguments]\n",
            "prior_loss_weight = 1.0\n",
            "\n",
            "[saving_arguments]\n",
            "save_model_as = \"safetensors\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "训练起来！过程中你可以在LoRA/output/hb_pro/sample目录下看训练过程中的图像生成效果。用于选择自己满意的LoRA模型。"
      ],
      "metadata": {
        "id": "yHMu-aazNbE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_prompt = os.path.join(config_dir, \"sample_prompt.txt\")\n",
        "config_file = os.path.join(config_dir, \"config_file.toml\")\n",
        "dataset_config = os.path.join(config_dir, \"dataset_config.toml\")\n",
        "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "\n",
        "accelerate_conf = {\n",
        "    \"config_file\" : accelerate_config,\n",
        "    \"num_cpu_threads_per_process\" : 1,\n",
        "}\n",
        "\n",
        "train_conf = {\n",
        "    \"sample_prompts\" : sample_prompt,\n",
        "    \"dataset_config\" : dataset_config,\n",
        "    \"config_file\" : config_file\n",
        "}\n",
        "\n",
        "def train(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "accelerate_args = train(accelerate_conf)\n",
        "train_args = train(train_conf)\n",
        "final_args = f\"accelerate launch {accelerate_args} train_network.py {train_args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cz2_7bONXq_",
        "outputId": "060dd170-eaef-45e6-cb84-3a5e750171ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading settings from /content/LoRA/config/config_file.toml...\n",
            "/content/LoRA/config/config_file\n",
            "prepare tokenizer\n",
            "Downloading (…)olve/main/vocab.json: 100% 961k/961k [00:00<00:00, 4.91MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 525k/525k [00:00<00:00, 4.07MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 389/389 [00:00<00:00, 2.04MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 905/905 [00:00<00:00, 6.81MB/s]\n",
            "update token length: 225\n",
            "Load dataset config from /content/LoRA/config/dataset_config.toml\n",
            "prepare images.\n",
            "found directory /content/LoRA/train_data/herburn_images contains 10 image files\n",
            "200 train images with repeating.\n",
            "0 reg images.\n",
            "no regularization images / 正則化画像が見つかりませんでした\n",
            "[Dataset 0]\n",
            "  batch_size: 6\n",
            "  resolution: (512, 512)\n",
            "  enable_bucket: True\n",
            "  min_bucket_reso: 256\n",
            "  max_bucket_reso: 1024\n",
            "  bucket_reso_steps: 64\n",
            "  bucket_no_upscale: False\n",
            "\n",
            "  [Subset 0 of Dataset 0]\n",
            "    image_dir: \"/content/LoRA/train_data/herburn_images\"\n",
            "    image_count: 10\n",
            "    num_repeats: 20\n",
            "    shuffle_caption: True\n",
            "    keep_tokens: 0\n",
            "    caption_dropout_rate: 0\n",
            "    caption_dropout_every_n_epoches: 0\n",
            "    caption_tag_dropout_rate: 0\n",
            "    color_aug: False\n",
            "    flip_aug: True\n",
            "    face_crop_aug_range: None\n",
            "    random_crop: False\n",
            "    token_warmup_min: 1,\n",
            "    token_warmup_step: 0,\n",
            "    is_reg: False\n",
            "    class_tokens: \n",
            "    caption_extension: .caption\n",
            "\n",
            "\n",
            "[Dataset 0]\n",
            "loading image sizes.\n",
            "100% 10/10 [00:00<00:00, 442.86it/s]\n",
            "make buckets\n",
            "number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）\n",
            "bucket 0: resolution (384, 640), count: 20\n",
            "bucket 1: resolution (448, 576), count: 60\n",
            "bucket 2: resolution (512, 512), count: 120\n",
            "mean ar error (without repeats): 0.025236564965376507\n",
            "prepare accelerator\n",
            "Using accelerator 0.15.0 or above.\n",
            "loading model for process 0/1\n",
            "load StableDiffusion checkpoint\n",
            "loading u-net: <All keys matched successfully>\n",
            "loading vae: <All keys matched successfully>\n",
            "Downloading (…)lve/main/config.json: 100% 4.52k/4.52k [00:00<00:00, 23.8MB/s]\n",
            "Downloading pytorch_model.bin: 100% 1.71G/1.71G [00:11<00:00, 145MB/s]\n",
            "loading text encoder: <All keys matched successfully>\n",
            "Replace CrossAttention.forward to use xformers\n",
            "[Dataset 0]\n",
            "caching latents.\n",
            "100% 4/4 [00:09<00:00,  2.36s/it]\n",
            "import network module: networks.lora\n",
            "create LoRA network. base dim (rank): 32, alpha: 16\n",
            "create LoRA for Text Encoder: 72 modules.\n",
            "create LoRA for U-Net: 192 modules.\n",
            "enable LoRA for text encoder\n",
            "enable LoRA for U-Net\n",
            "prepare optimizer, data loader etc.\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
            "================================================================================\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda-11.8/targets/x86_64-linux/lib/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n",
            "use 8-bit AdamW optimizer | {}\n",
            "override steps. steps for 10 epochs is / 指定エポックまでのステップ数: 340\n",
            "running training / 学習開始\n",
            "  num train images * repeats / 学習画像の数×繰り返し回数: 200\n",
            "  num reg images / 正則化画像の数: 0\n",
            "  num batches per epoch / 1epochのバッチ数: 34\n",
            "  num epochs / epoch数: 10\n",
            "  batch size per device / バッチサイズ: 6\n",
            "  gradient accumulation steps / 勾配を合計するステップ数 = 1\n",
            "  total optimization steps / 学習ステップ数: 340\n",
            "steps:   0% 0/340 [00:00<?, ?it/s]epoch 1/10\n",
            "steps:  10% 34/340 [00:52<07:54,  1.55s/it, loss=0.157]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000001.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 34\n",
            "prompt: masterpiece, best quality, 1girl,moyou，very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: EasyNegativeV2,(badhandv4:1.2),  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:15,  1.74it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:09,  2.81it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:07,  3.46it/s]\u001b[A\n",
            " 14% 4/28 [00:01<00:06,  3.82it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:05,  3.94it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:05,  4.16it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  4.31it/s]\u001b[A\n",
            " 29% 8/28 [00:02<00:04,  4.44it/s]\u001b[A\n",
            " 32% 9/28 [00:02<00:04,  4.48it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:04,  4.46it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  4.50it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  4.57it/s]\u001b[A\n",
            " 46% 13/28 [00:03<00:03,  4.60it/s]\u001b[A\n",
            " 50% 14/28 [00:03<00:03,  4.60it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  4.61it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.61it/s]\u001b[A\n",
            " 61% 17/28 [00:04<00:02,  4.66it/s]\u001b[A\n",
            " 64% 18/28 [00:04<00:02,  4.64it/s]\u001b[A\n",
            " 68% 19/28 [00:04<00:01,  4.64it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.64it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.63it/s]\u001b[A\n",
            " 79% 22/28 [00:05<00:01,  4.64it/s]\u001b[A\n",
            " 82% 23/28 [00:05<00:01,  4.67it/s]\u001b[A\n",
            " 86% 24/28 [00:05<00:00,  4.64it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.64it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  4.66it/s]\u001b[A\n",
            " 96% 27/28 [00:06<00:00,  4.69it/s]\u001b[A\n",
            "100% 28/28 [00:06<00:00,  4.38it/s]\n",
            "epoch 2/10\n",
            "steps:  20% 68/340 [01:52<07:29,  1.65s/it, loss=0.137]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000002.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 68\n",
            "prompt: masterpiece, best quality, 1girl,moyou，very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: EasyNegativeV2,(badhandv4:1.2),  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.08it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  5.01it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:05,  4.95it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  4.90it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:04,  4.70it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  4.78it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  4.84it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:04,  4.86it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  4.84it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:03,  4.79it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  4.82it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  4.84it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  4.87it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  4.81it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  4.79it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.82it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  4.84it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:02,  4.84it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  4.84it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.82it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.85it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  4.83it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:01,  4.84it/s]\u001b[A\n",
            " 86% 24/28 [00:04<00:00,  4.82it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.82it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  4.82it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  4.83it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  4.83it/s]\n",
            "epoch 3/10\n",
            "steps:  30% 102/340 [02:51<06:39,  1.68s/it, loss=0.115]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000003.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 102\n",
            "prompt: masterpiece, best quality, 1girl,moyou，very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: EasyNegativeV2,(badhandv4:1.2),  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.04it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  4.99it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:05,  4.96it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  4.95it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:04,  4.71it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  4.75it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  4.80it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:04,  4.82it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  4.76it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:03,  4.75it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  4.81it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  4.85it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  4.86it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  4.76it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  4.76it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.79it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  4.83it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:02,  4.81it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  4.77it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.75it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.77it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  4.82it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:01,  4.84it/s]\u001b[A\n",
            " 86% 24/28 [00:04<00:00,  4.80it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.78it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  4.81it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  4.82it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  4.81it/s]\n",
            "epoch 4/10\n",
            "steps:  40% 136/340 [03:48<05:43,  1.68s/it, loss=0.117]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000004.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 136\n",
            "prompt: masterpiece, best quality, 1girl,moyou，very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: EasyNegativeV2,(badhandv4:1.2),  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.10it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  5.00it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:05,  4.97it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  4.94it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:04,  4.71it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  4.79it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  4.84it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:04,  4.85it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  4.75it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:03,  4.74it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  4.79it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  4.83it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  4.85it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  4.77it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  4.78it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.79it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  4.81it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:02,  4.80it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  4.76it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.78it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.78it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  4.80it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:01,  4.77it/s]\u001b[A\n",
            " 86% 24/28 [00:05<00:00,  4.74it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.76it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  4.76it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  4.79it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  4.80it/s]\n",
            "epoch 5/10\n",
            "steps:  50% 170/340 [04:47<04:47,  1.69s/it, loss=0.119]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000005.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 170\n",
            "prompt: masterpiece, best quality, 1girl,moyou，very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: EasyNegativeV2,(badhandv4:1.2),  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  4.96it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  4.93it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:05,  4.88it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  4.88it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:04,  4.70it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  4.76it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  4.80it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:04,  4.82it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  4.76it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:03,  4.77it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  4.78it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  4.79it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  4.81it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  4.75it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  4.76it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.79it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  4.80it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:02,  4.83it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  4.77it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.78it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.79it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  4.82it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:01,  4.83it/s]\u001b[A\n",
            " 86% 24/28 [00:05<00:00,  4.78it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.78it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  4.80it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  4.82it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  4.80it/s]\n",
            "epoch 6/10\n",
            "steps:  60% 204/340 [05:47<03:51,  1.70s/it, loss=0.123]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000006.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 204\n",
            "prompt: masterpiece, best quality, 1girl,moyou，very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: EasyNegativeV2,(badhandv4:1.2),  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.12it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  5.01it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:05,  4.94it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  4.90it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:04,  4.68it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  4.75it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  4.79it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:04,  4.84it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  4.77it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:03,  4.77it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  4.78it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  4.81it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  4.85it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  4.78it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  4.79it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.81it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  4.79it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:02,  4.80it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  4.77it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.78it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.80it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  4.80it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:01,  4.80it/s]\u001b[A\n",
            " 86% 24/28 [00:04<00:00,  4.80it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.82it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  4.83it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  4.81it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  4.81it/s]\n",
            "epoch 7/10\n",
            "steps:  70% 238/340 [06:46<02:54,  1.71s/it, loss=0.125]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000007.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 238\n",
            "prompt: masterpiece, best quality, 1girl,moyou，very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: EasyNegativeV2,(badhandv4:1.2),  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.06it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  5.00it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:05,  4.97it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  4.92it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:04,  4.65it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  4.72it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  4.80it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:04,  4.82it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  4.76it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:03,  4.74it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  4.78it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  4.82it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  4.85it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  4.78it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  4.79it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.81it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  4.84it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:02,  4.86it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  4.82it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.83it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.84it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  4.86it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:01,  4.87it/s]\u001b[A\n",
            " 86% 24/28 [00:04<00:00,  4.82it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.82it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  4.77it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  4.77it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  4.81it/s]\n",
            "epoch 8/10\n",
            "steps:  80% 272/340 [07:45<01:56,  1.71s/it, loss=0.13] saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000008.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 272\n",
            "prompt: masterpiece, best quality, 1girl,moyou，very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: EasyNegativeV2,(badhandv4:1.2),  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.01it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  4.97it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:05,  4.95it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  4.93it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:04,  4.73it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  4.78it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  4.79it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:04,  4.82it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  4.78it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:03,  4.75it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  4.79it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  4.81it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  4.86it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  4.79it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  4.79it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.78it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  4.80it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:02,  4.83it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  4.81it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.83it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.83it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  4.80it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:01,  4.82it/s]\u001b[A\n",
            " 86% 24/28 [00:04<00:00,  4.78it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.80it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  4.80it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  4.77it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  4.81it/s]\n",
            "epoch 9/10\n",
            "steps:  90% 306/340 [08:43<00:58,  1.71s/it, loss=0.129]saving checkpoint: /content/LoRA/output/hb_pro/hb_pro-000009.safetensors\n",
            "generating sample images at step / サンプル画像生成 ステップ: 306\n",
            "prompt: masterpiece, best quality, 1girl,moyou，very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: EasyNegativeV2,(badhandv4:1.2),  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  5.05it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  4.95it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:05,  4.90it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  4.89it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:04,  4.69it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  4.74it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  4.80it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:04,  4.82it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:03,  4.77it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:03,  4.77it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  4.78it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  4.81it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  4.85it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  4.81it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  4.77it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.77it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  4.81it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:02,  4.79it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  4.80it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.79it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.81it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  4.84it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:01,  4.83it/s]\u001b[A\n",
            " 86% 24/28 [00:04<00:00,  4.84it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.80it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  4.79it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  4.82it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  4.81it/s]\n",
            "epoch 10/10\n",
            "steps: 100% 340/340 [09:42<00:00,  1.71s/it, loss=0.124]generating sample images at step / サンプル画像生成 ステップ: 340\n",
            "prompt: masterpiece, best quality, 1girl,moyou，very short haircut and a pink shirt, looking at viewer, simple background  \n",
            "negative_prompt: EasyNegativeV2,(badhandv4:1.2),  \n",
            "height: 512\n",
            "width: 512\n",
            "sample_steps: 28\n",
            "scale: 7.0\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:05,  4.96it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:05,  4.93it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:05,  4.95it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:04,  4.89it/s]\u001b[A\n",
            " 18% 5/28 [00:01<00:04,  4.66it/s]\u001b[A\n",
            " 21% 6/28 [00:01<00:04,  4.72it/s]\u001b[A\n",
            " 25% 7/28 [00:01<00:04,  4.74it/s]\u001b[A\n",
            " 29% 8/28 [00:01<00:04,  4.78it/s]\u001b[A\n",
            " 32% 9/28 [00:01<00:04,  4.74it/s]\u001b[A\n",
            " 36% 10/28 [00:02<00:03,  4.74it/s]\u001b[A\n",
            " 39% 11/28 [00:02<00:03,  4.78it/s]\u001b[A\n",
            " 43% 12/28 [00:02<00:03,  4.81it/s]\u001b[A\n",
            " 46% 13/28 [00:02<00:03,  4.81it/s]\u001b[A\n",
            " 50% 14/28 [00:02<00:02,  4.74it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  4.75it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.78it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:02,  4.79it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:02,  4.82it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  4.77it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.79it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  4.75it/s]\u001b[A\n",
            " 79% 22/28 [00:04<00:01,  4.78it/s]\u001b[A\n",
            " 82% 23/28 [00:04<00:01,  4.79it/s]\u001b[A\n",
            " 86% 24/28 [00:05<00:00,  4.74it/s]\u001b[A\n",
            " 89% 25/28 [00:05<00:00,  4.76it/s]\u001b[A\n",
            " 93% 26/28 [00:05<00:00,  4.78it/s]\u001b[A\n",
            " 96% 27/28 [00:05<00:00,  4.80it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  4.78it/s]\n",
            "save trained model to /content/LoRA/output/hb_pro/hb_pro.safetensors\n",
            "model saved.\n",
            "steps: 100% 340/340 [09:49<00:00,  1.73s/it, loss=0.124]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PE3ES-oiVkk4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LoRA/output/hb_pro/目录下的safetensor文件就是我们得到的LoRA模型，下载到WebUI就可以直接使用。"
      ],
      "metadata": {
        "id": "-lW9BqxjCHjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "试试推理？"
      ],
      "metadata": {
        "id": "C9v0773zVlDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "network_weight = \"/content/LoRA/output/hb_pro/hb_pro.safetensors\"\n",
        "network_mul = 1\n",
        "network_module = \"networks.lora\"\n",
        "network_args = \"\"\n",
        "\n",
        "v2 = False\n",
        "v_parameterization = False\n",
        "prompt = \"masterpiece, best quality, 1girl moyou ( ink sketch) fantasy, surreal muted color ( Russ Mills Anna Dittmann)\"   # 你要测试的prompt\n",
        "negative = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\"\n",
        "model = pretrained_model_name_or_path\n",
        "vae = \"\"\n",
        "outdir = \"/content/tmp\"  # 图片存储的路径\n",
        "scale = 7\n",
        "sampler = \"euler_a\"\n",
        "steps = 20\n",
        "precision = \"fp16\"\n",
        "width = 512\n",
        "height = 768\n",
        "images_per_prompt = 4\n",
        "batch_size = 4\n",
        "clip_skip = 2\n",
        "seed = 1024\n",
        "\n",
        "final_prompt = f\"{prompt} --n {negative}\"\n",
        "\n",
        "config = {\n",
        "    \"v2\": v2,\n",
        "    \"v_parameterization\": v_parameterization,\n",
        "    \"network_module\": network_module,\n",
        "    \"network_weight\": network_weight,\n",
        "    \"network_mul\": float(network_mul),\n",
        "    \"network_args\": eval(network_args) if network_args else None,\n",
        "    \"ckpt\": model,\n",
        "    \"outdir\": outdir,\n",
        "    \"xformers\": True,\n",
        "    \"vae\": vae if vae else None,\n",
        "    \"fp16\": True,\n",
        "    \"W\": width,\n",
        "    \"H\": height,\n",
        "    \"seed\": seed if seed > 0 else None,\n",
        "    \"scale\": scale,\n",
        "    \"sampler\": sampler,\n",
        "    \"steps\": steps,\n",
        "    \"max_embeddings_multiples\": 3,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"images_per_prompt\": images_per_prompt,\n",
        "    \"clip_skip\": clip_skip if not v2 else None,\n",
        "    \"prompt\": final_prompt,\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python gen_img_diffusers.py {args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMetKpLVNr79",
        "outputId": "c50c61c6-6a5c-4710-8dc3-a1a7eb886240"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load StableDiffusion checkpoint\n",
            "loading u-net: <All keys matched successfully>\n",
            "loading vae: <All keys matched successfully>\n",
            "loading text encoder: <All keys matched successfully>\n",
            "Replace CrossAttention.forward to use NAI style Hypernetwork and xformers\n",
            "loading tokenizer\n",
            "prepare tokenizer\n",
            "import network module: networks.lora\n",
            "load network weights from: /content/LoRA/output/hb_pro/hb_pro.safetensors\n",
            "create LoRA network from weights\n",
            "create LoRA for Text Encoder: 72 modules.\n",
            "create LoRA for U-Net: 192 modules.\n",
            "enable LoRA for text encoder\n",
            "enable LoRA for U-Net\n",
            "weights are loaded: <All keys matched successfully>\n",
            "pipeline is ready.\n",
            "iteration 1/1\n",
            "prompt 1/1: masterpiece, best quality, 1girl moyou ( ink sketch) fantasy, surreal muted color ( Russ Mills Anna Dittmann)\n",
            "negative prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\n",
            "100% 20/20 [00:23<00:00,  1.16s/it]\n",
            "done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "点开这个路径：/content/tmp，查看你生成的图片！可以更换代码里的prompt反复尝试几次。权重和图片记得保存本地，不然colab断开就都没了。"
      ],
      "metadata": {
        "id": "Ol9_GsBhDRHI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HlC1R3oIWSMJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在你的WebUI里面玩起来？\n",
        "- 配合LoRA风格模型\n",
        "- 配合不同基础模型\n",
        "- 配合超分模块\n",
        "- 配合不同的prompt"
      ],
      "metadata": {
        "id": "7_5i8GPiWUQT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GdoQU998ExBv"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}